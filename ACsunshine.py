
from __future__ import annotations

import os
from typing import Optional, Tuple, List, Dict, Any

import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import matplotlib

# ä¿®å¤ matplotlib ä¸­æ–‡ä¹±ç ï¼šä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—ä½“
matplotlib.rcParams["font.sans-serif"] = ["SimHei", "Microsoft YaHei", "SimSun", "KaiTi", "FangSong"]
matplotlib.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹æ¡†

import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# é¿å… OpenMP ä¸ PyTorch å†²çªï¼ˆè‹¥æœªç”¨ MKL å¯å¿½ç•¥ï¼‰
os.environ.setdefault("KMP_DUPLICATE_LIB_OK", "TRUE")


# =============================================================================
# 0. é…ç½®ç±»ï¼šç»Ÿä¸€ç®¡ç†è¶…å‚æ•°
# =============================================================================

class TrainingConfig:
    """è®­ç»ƒé…ç½®ç±»ï¼šç»Ÿä¸€ç®¡ç†æ‰€æœ‰è¶…å‚æ•°ï¼Œä¾¿äºè°ƒä¼˜å’Œå®éªŒ"""
    # å­¦ä¹ ç‡é…ç½®
    LR_ACTOR_BASE = 3e-4
    LR_CRITIC_BASE = 4e-4
    LR_MULTIPLIER_DOUBLE_DIODE = 1.5  # åŒäºŒæç®¡æ¨¡å‹å­¦ä¹ ç‡å€æ•°
    
    # æ¢ç´¢é…ç½®
    EXPLORATION_INITIAL = 1.2
    EXPLORATION_FINAL = 0.4
    EXPLORATION_BOOST_FACTOR = 1.2  # åæœŸæ¢ç´¢å¢å¼ºå€æ•°
    EXPLORATION_BOOST_THRESHOLD = 50  # è§¦å‘æ¢ç´¢å¢å¼ºçš„epoch
    
    # å™ªå£°é…ç½®
    NOISE_SCALE_BASE = 0.02
    NOISE_THRESHOLD_EPOCH = 30
    
    # é‡å¯é…ç½®ï¼ˆå·²æ”¾å®½ï¼šé¿å…é¢‘ç¹ç ´åå·²å­¦ä¹ çš„çŸ¥è¯†ï¼‰
    RESTART_PATIENCE = 100  # è¿ç»­æœªæ”¹å–„epochæ•°ï¼ˆä»15æé«˜åˆ°100ï¼Œé¿å…é¢‘ç¹é‡å¯ï¼‰
    RESTART_NOISE_SCALE = 0.05  # é‡å¯æ—¶çš„å™ªå£°å¼ºåº¦ï¼ˆä»0.15é™ä½åˆ°0.05ï¼Œæ›´æ¸©å’Œï¼‰
    
    # å¥–åŠ±æƒé‡é…ç½®ï¼ˆé™ä½å½¢çŠ¶å¥–åŠ±æƒé‡ï¼Œå¼ºè°ƒè¯¯å·®ä¼˜åŒ–ï¼Œå‡å°‘çŸ­è§†ï¼‰
    REWARD_WEIGHTS = {
        'sparse': 0.8,    # è¯¯å·®ä¸‹é™å¥–åŠ±ï¼ˆä»0.6æé«˜åˆ°0.8ï¼Œæ›´å¼ºè°ƒè¯¯å·®ä¼˜åŒ–ï¼‰
        'flat': 0.1,      # I_phå¥–åŠ±ï¼ˆä»0.15é™ä½åˆ°0.1ï¼Œå‡å°‘å¹²æ‰°ï¼‰
        'knee': 0.05,     # I0å¥–åŠ±ï¼ˆä»0.15é™ä½åˆ°0.05ï¼Œå‡å°‘å¹²æ‰°ï¼‰
        'rs': 0.025,      # Rså¥–åŠ±ï¼ˆä»0.05é™ä½åˆ°0.025ï¼‰
        'rsh': 0.025,     # Rshå¥–åŠ±ï¼ˆä»0.05é™ä½åˆ°0.025ï¼‰
        'boundary': 0.0   # è¾¹ç•Œæƒ©ç½šï¼ˆè®¾ä¸º0ç¦ç”¨ï¼‰
    }
    
    # è¾¹ç•Œæƒ©ç½šé…ç½®ï¼ˆå·²ç¦ç”¨ï¼šç§»é™¤è¾¹ç•Œæƒ©ç½šä»¥å…è®¸æ¢ç´¢è¾¹ç•Œé™„è¿‘çš„è§£ï¼‰
    BOUNDARY_MARGIN = 0.1  # è¾¹ç•Œæ£€æµ‹èŒƒå›´ï¼ˆ10%ï¼‰
    BOUNDARY_TOLERANCE = 1e-6  # è¾¹ç•Œåˆ¤æ–­å®¹å·®
    BOUNDARY_PENALTY_SCALE = 0.0  # è¾¹ç•Œæƒ©ç½šå¼ºåº¦ï¼ˆè®¾ä¸º0ç¦ç”¨è¾¹ç•Œæƒ©ç½šï¼‰
    
    # å…¶ä»–é…ç½®
    REWARD_SCALE = 1000.0
    DEFAULT_ALPHA = 0.5  # å‚æ•°æ›´æ–°æ­¥é•¿
    ENTROPY_COEF = 0.03  # ç†µæ­£åˆ™åŒ–ç³»æ•°
    
    # å›ºå®šå‚æ•°é…ç½®ï¼ˆç®€åŒ–ä¼˜åŒ–é—®é¢˜ï¼‰
    FIX_N1 = True   # æ˜¯å¦å›ºå®šn1
    FIX_N2 = True   # æ˜¯å¦å›ºå®šn2
    FIXED_N1_VALUE = 1.0   # å›ºå®šn1çš„å€¼
    FIXED_N2_VALUE = 1.5   # å›ºå®šn2çš„å€¼


# =============================================================================
# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
# =============================================================================

def load_excel_and_preprocess(excel_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, float, float]:
    """
    ä» Excel è¯»å– IV æ•°æ®å¹¶é¢„å¤„ç†ã€‚
    åˆ—ï¼šç¬¬ 0 åˆ—ç”µå‹ Vï¼Œç¬¬ 1 åˆ—ç”µæµ Iã€‚
    è¿”å›ï¼šV_processed, I_meas_processed, V_original, I_original, I_min, I_max
    """
    df = pd.read_excel(excel_path, header=None, usecols=[0, 1], skiprows=1)
    V_orig = df.iloc[:, 0].astype(float).values
    I_orig = df.iloc[:, 1].astype(float).values
    valid = np.isfinite(V_orig) & np.isfinite(I_orig)
    V = V_orig[valid]
    I = I_orig[valid]
    I_pos = I[I > 0]
    I_min = float(np.min(I_pos)) if len(I_pos) > 0 else 1e-16
    I_max = float(np.max(I_pos)) if len(I_pos) > 0 else 1e-4
    return V, I, V_orig, I_orig, I_min, I_max


# =============================================================================
# 2. å¤ªé˜³èƒ½ç”µæ± å•äºŒæç®¡æ¨¡å‹ä¸ç›®æ ‡å‡½æ•°
# =============================================================================

def solar_cell_model(
    V: np.ndarray,
    params: np.ndarray,
    I_min: float,
    I_max: float,
) -> np.ndarray:
    # ğŸ”¥ åŒäºŒæç®¡æ¨¡å‹ï¼šæ”¯æŒ7ä¸ªå‚æ•° [I_ph, I01, I02, n1, n2, Rs, Rsh]
    if len(params) == 7:
        I_ph, I01, I02, n1, n2, Rs, Rsh = params
        use_double_diode = True
    else:
        # å‘åå…¼å®¹ï¼šå•äºŒæç®¡æ¨¡å‹ [I_ph, I0, n, Rs, Rsh]
        I_ph, I0, n, Rs, Rsh = params
        use_double_diode = False
        # ä¸ºå…¼å®¹æ€§ï¼Œè®¾ç½®åŒäºŒæç®¡å‚æ•°
        I01, I02, n1, n2 = I0, 0.0, n, 2.0
    
    Vt = 0.026
    clip_min, clip_max = -50.0, 150.0
    I_out = np.zeros_like(V, dtype=np.float64)
    prev_I = float(I_ph)  # ä¸Šä¸€ç”µå‹ç‚¹ç”µæµï¼Œç”¨ä½œé«˜å‹åŒºè¿­ä»£åˆå€¼ï¼Œåˆ©äºé™¡é™æ®µæ”¶æ•›
    
    # ä¿®å¤ï¼šclipèŒƒå›´åº”è¯¥åŸºäºç‰©ç†çº¦æŸï¼Œè€Œä¸æ˜¯æ•°æ®èŒƒå›´
    # ç”µæµåº”è¯¥åœ¨ [0, I_ph*1.5] èŒƒå›´ï¼Œè€Œä¸æ˜¯ [I_min*0.1, I_max*2]
    clip_min_current = 0.0  # ç”µæµä¸èƒ½ä¸ºè´Ÿ
    clip_max_current = I_ph * 1.5  # ç”µæµä¸èƒ½è¶…è¿‡I_phå¤ªå¤šï¼ˆè€ƒè™‘æµ‹é‡è¯¯å·®ï¼‰
    V_max_ref = float(np.max(V)) if len(V) > 0 else 100.0  # ç”¨äºä½ç”µå‹åˆ¤æ–­

    for i, v in enumerate(V):

        if use_double_diode:
            # åŒäºŒæç®¡æ¨¡å‹ï¼šf(I) = I - (I_ph - I01*exp1 - I02*exp2 - shunt)
            def f(I_val: float) -> float:
                x1 = (v + I_val * Rs) / (n1 * Vt)
                x2 = (v + I_val * Rs) / (n2 * Vt)
                x1_clipped = np.clip(x1, clip_min, clip_max)
                x2_clipped = np.clip(x2, clip_min, clip_max)
                exp_term1 = np.exp(x1_clipped) - 1.0
                exp_term2 = np.exp(x2_clipped) - 1.0
                shunt = (v + I_val * Rs) / Rsh
                return I_val - (I_ph - I01 * exp_term1 - I02 * exp_term2 - shunt)

            def f_prime(I_val: float) -> float:
                x1 = (v + I_val * Rs) / (n1 * Vt)
                x2 = (v + I_val * Rs) / (n2 * Vt)
                x1_clipped = np.clip(x1, clip_min, clip_max)
                x2_clipped = np.clip(x2, clip_min, clip_max)
                exp_term1 = np.exp(x1_clipped)
                exp_term2 = np.exp(x2_clipped)
                return 1.0 + (I01 * Rs / (n1 * Vt)) * exp_term1 + (I02 * Rs / (n2 * Vt)) * exp_term2 + Rs / Rsh
        else:
            # å•äºŒæç®¡æ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
            def f(I_val: float) -> float:
                x = (v + I_val * Rs) / (n * Vt)
                x_clipped = np.clip(x, clip_min, clip_max)
                exp_term = np.exp(x_clipped) - 1.0
                shunt = (v + I_val * Rs) / Rsh
                return I_val - (I_ph - I0 * exp_term - shunt)

            def f_prime(I_val: float) -> float:
                x = (v + I_val * Rs) / (n * Vt)
                x_clipped = np.clip(x, clip_min, clip_max)
                exp_term = np.exp(x_clipped)
                return 1.0 + (I0 * Rs / (n * Vt)) * exp_term + Rs / Rsh

        init_I = prev_I if i > 0 else float(I_ph)
        # ä¼˜åŒ–ï¼šå‡å°‘åˆå§‹å€¼ä¼˜åŒ–è¿­ä»£æ¬¡æ•°ä»5åˆ°3ï¼Œå¤§å¤šæ•°æƒ…å†µ3æ¬¡è¶³å¤Ÿï¼Œæå‡é€Ÿåº¦
        for _ in range(3):  # ä»5å‡å°‘åˆ°3ï¼Œæå‡é€Ÿåº¦ï¼Œä¸å½±å“ç²¾åº¦
            if not np.isfinite(init_I):
                init_I = I_ph  # å¦‚æœå¼‚å¸¸ï¼Œé‡ç½®ä¸ºI_ph
                break
            if init_I <= 0:
                init_I = I_ph * 0.95  # å¦‚æœä¸ºè´Ÿæˆ–0ï¼Œè®¾ç½®ä¸ºæ¥è¿‘I_phçš„å€¼
                break
            fp = f_prime(init_I)
            if abs(fp) < 1e-12:
                break
            init_I = init_I - f(init_I) / fp
            # ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†çº¦æŸï¼Œç¡®ä¿ç”µæµåœ¨åˆç†èŒƒå›´
            init_I = float(np.clip(init_I, 0.0, clip_max_current))

        # ä¿®å¤ï¼šç¡®ä¿åˆå§‹å€¼åˆç†
        if init_I <= 0 or not np.isfinite(init_I):
            init_I = I_ph * 0.95  # å¦‚æœåˆå§‹å€¼å¼‚å¸¸ï¼Œä½¿ç”¨æ¥è¿‘I_phçš„å€¼
        
        I_i = init_I
        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆä»100å‡å°‘åˆ°50ï¼‰ï¼Œå¤§å¤šæ•°æƒ…å†µ30æ¬¡å†…æ”¶æ•›
        # ä¿æŒç²¾åº¦ï¼šæå‰é€€å‡ºæ¡ä»¶ç¡®ä¿æ”¶æ•›ï¼Œä¸å½±å“æ•ˆæœ
        for iter_count in range(50):  # ä»100å‡å°‘åˆ°50ï¼Œé€Ÿåº¦æå‡çº¦2å€
            # ä½¿ç”¨ç‰›é¡¿æ³•è€Œéå›ºå®šç‚¹è¿­ä»£ï¼Œæé«˜é«˜ç”µå‹åŒºæ”¶æ•›æ€§ï¼Œç¡®ä¿é™¡é™æ®µèƒ½æ­£ç¡®è®¡ç®—
            f_val = f(I_i)
            fp_val = f_prime(I_i)
            if abs(fp_val) > 1e-12:
                I_new = I_i - f_val / fp_val
            else:
                # å…œåº•ï¼šå¦‚æœå¯¼æ•°å¤ªå°ï¼Œä½¿ç”¨ç®€åŒ–å…¬å¼
                if use_double_diode:
                    x1 = (v + I_i * Rs) / (n1 * Vt)
                    x2 = (v + I_i * Rs) / (n2 * Vt)
                    x1_clipped = np.clip(x1, clip_min, clip_max)
                    x2_clipped = np.clip(x2, clip_min, clip_max)
                    exp_term1 = np.exp(x1_clipped) - 1.0
                    exp_term2 = np.exp(x2_clipped) - 1.0
                    shunt = (v + I_i * Rs) / Rsh
                    I_new = I_ph - I01 * exp_term1 - I02 * exp_term2 - shunt
                else:
                    x = (v + I_i * Rs) / (n * Vt)
                    x_clipped = np.clip(x, clip_min, clip_max)
                    exp_term = np.exp(x_clipped) - 1.0
                    shunt = (v + I_i * Rs) / Rsh
                    I_new = I_ph - I0 * exp_term - shunt
            
            # ä¿®å¤ï¼šä½¿ç”¨ç‰©ç†çº¦æŸï¼Œç¡®ä¿ç”µæµåœ¨åˆç†èŒƒå›´
            # å…³é”®ï¼šä½ç”µå‹æ—¶ç”µæµåº”è¯¥æ¥è¿‘I_phï¼Œä¸èƒ½å¤ªå°
            if v < 0.1 * V_max_ref:
                # ä½ç”µå‹æ—¶ï¼Œç¡®ä¿ç”µæµä¸ä¼šå¤ªå°ï¼ˆè‡³å°‘æ˜¯I_phçš„70%ï¼‰
                I_new = float(np.clip(I_new, I_ph * 0.7, clip_max_current))
            else:
                # é«˜ç”µå‹æ—¶ï¼Œä½¿ç”¨æ­£å¸¸çº¦æŸ
                I_new = float(np.clip(I_new, 0.0, clip_max_current))
            
            # ä¸¥æ ¼æ”¶æ•›åˆ¤æ–­ï¼šä¿æŒ1e-8ç²¾åº¦è¦æ±‚ï¼Œä¸å½±å“æ•ˆæœ
            if abs(I_new - I_i) < 1e-8:
                I_i = I_new
                break
            # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šæå‰é€€å‡ºæ¡ä»¶æ›´å®½æ¾ï¼ˆä»30æ¬¡å‡å°‘åˆ°20æ¬¡ï¼‰ï¼Œé€Ÿåº¦æå‡
            # æ³¨æ„ï¼šåœ¨æ›´æ–°I_iä¹‹å‰æ£€æŸ¥ï¼Œæ‰€ä»¥æ£€æŸ¥çš„æ˜¯I_newå’Œå½“å‰I_içš„å·®å€¼
            if iter_count >= 20 and abs(I_new - I_i) < 1e-5:  # ä»30æ¬¡å‡å°‘åˆ°20æ¬¡ï¼Œä»1e-6æ”¾å®½åˆ°1e-5
                I_i = I_new
                break
            I_i = I_new
        
        # ä¿®å¤ï¼šä½ç”µå‹æ—¶çš„ç‰¹æ®Šå¤„ç†ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
        # åœ¨ä½ç”µå‹æ—¶ï¼ˆV < 0.15*V_maxï¼‰ï¼Œç”µæµåº”è¯¥æ¥è¿‘I_phï¼Œç›´æ¥ä½¿ç”¨ç®€åŒ–å…¬å¼
        if len(V) > 0 and v < 0.15 * V_max_ref:
            # ä½ç”µå‹æ—¶ï¼Œä½¿ç”¨ç®€åŒ–å…¬å¼ï¼šI â‰ˆ I_ph - V/Rshï¼ˆå¿½ç•¥äºŒæç®¡é¡¹å’ŒI*Rsé¡¹ï¼‰
            I_simple = I_ph - v / Rsh
            # å¦‚æœè¿­ä»£ç»“æœå¼‚å¸¸å°ï¼ˆå°äºç®€åŒ–å…¬å¼çš„50%ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ç®€åŒ–å…¬å¼
            if I_i < I_simple * 0.5:
                I_i = I_simple
            # ç¡®ä¿ä½ç”µå‹æ—¶ç”µæµä¸ä¼šå¤ªå°ï¼ˆè‡³å°‘æ˜¯I_phçš„85%ï¼‰
            if I_i < I_ph * 0.85:
                I_i = I_ph * 0.85
        
        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿ç”µæµä¸ä¸º0ä¸”åˆç†ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
        if I_i <= 0 or not np.isfinite(I_i):
            # å¦‚æœè¿­ä»£ç»“æœå¼‚å¸¸ï¼Œä½¿ç”¨ç®€åŒ–å…¬å¼
            I_i = max(I_ph - v / Rsh, I_ph * 0.9)
        
        # æœ€ç»ˆè¾“å‡ºï¼šç¡®ä¿ç”µæµåœ¨åˆç†èŒƒå›´
        I_out[i] = max(I_i, I_ph * 0.8) if I_ph > 0 else I_i
        prev_I = float(I_out[i])

    return I_out


def objective_function(
    params: np.ndarray,
    V: np.ndarray,
    I_meas: np.ndarray,
    I_min: float,
    I_max: float,
    add_shape_constraint: bool = True,  # æ–°å¢ï¼šæ˜¯å¦æ·»åŠ å½¢çŠ¶çº¦æŸ
) -> float:
    """
    ç›®æ ‡å‡½æ•° fï¼šå½’ä¸€åŒ– RMSEï¼Œå¹¶å¯¹é«˜ç”µå‹åŒºï¼ˆé™¡é™åŒºï¼‰åŠ æƒï¼Œä»¥æ”¹å–„åæœŸæ‹Ÿåˆä¸ä¸‹é™é—®é¢˜ã€‚
    æ–°å¢ï¼šæ·»åŠ å½¢çŠ¶çº¦æŸï¼Œå³ä½¿æ•°æ®ç¼ºå¤±ä¹Ÿèƒ½å­¦ä¹ åˆ°åˆç†çš„æ›²çº¿å½¢çŠ¶ã€‚
    f = sqrt( sum_i ( w_i * rel_i^2 ) / sum(w) )ï¼Œrel_i = (I_meas_i - I_sim_i)/max(I_meas)ï¼›
    å½“ V_i >= 0.75*max(V) æ—¶ w_i=2ï¼Œå¦åˆ™ w_i=1ã€‚
    """
    if len(V) == 0 or len(I_meas) == 0:
        return 1e10
    I_sim = solar_cell_model(V, params, I_min, I_max)
    if np.any(np.isnan(I_sim)) or np.any(np.isinf(I_sim)):
        return 1e10
    valid = (I_meas > 1e-10) & np.isfinite(I_meas)
    if not np.any(valid):
        return 1e10
    I_m = I_meas[valid]
    I_s = I_sim[valid]
    V_flat = np.asarray(V, dtype=np.float64).flatten()
    n_pts = len(I_meas)
    if len(V_flat) < n_pts:
        V_flat = np.pad(V_flat, (0, n_pts - len(V_flat)), mode="edge")
    V_m = V_flat[:n_pts][valid]
    rel = (I_m - I_s) / (np.max(I_m) + 1e-12)
    # æ”¹è¿›ï¼šåˆ†æ®µåŠ æƒç­–ç•¥ï¼Œæ›´å¥½åœ°å¹³è¡¡ä¸åŒç”µå‹åŒºåŸŸçš„æ‹Ÿåˆ
    # ä½ç”µå‹åŒºï¼ˆå¹³å¦æ®µï¼‰ï¼šæƒé‡ 1.0
    # ä¸­ç”µå‹åŒºï¼ˆè¿‡æ¸¡æ®µï¼‰ï¼šæƒé‡ 1.5
    # é«˜ç”µå‹åŒºï¼ˆé™¡é™æ®µï¼‰ï¼šæƒé‡ 2.5
    weight_low_voltage = 1.0
    weight_mid_voltage = 1.5   # æ–°å¢ï¼šè¿‡æ¸¡æ®µæƒé‡
    weight_high_voltage = 3.5  # ä»2.5æé«˜åˆ°3.5ï¼Œæ›´å¼ºè°ƒé™¡é™æ®µæ‹Ÿåˆè´¨é‡
    mid_voltage_frac = 0.60    # æ–°å¢ï¼šè¿‡æ¸¡æ®µé˜ˆå€¼
    high_voltage_frac = 0.85   # ä»0.80æé«˜åˆ°0.85ï¼Œæ›´ç²¾ç¡®åœ°å®šä½é™¡é™æ®µ
    V_max = float(np.max(V_m)) if len(V_m) > 0 else 1.0
    V_norm = V_m / (V_max + 1e-12)
    # åˆ†æ®µåŠ æƒ
    w = np.ones_like(V_m) * weight_low_voltage
    w[(V_norm >= mid_voltage_frac) & (V_norm < high_voltage_frac)] = weight_mid_voltage
    w[V_norm >= high_voltage_frac] = weight_high_voltage
    loss = np.sqrt((1.0 / (np.sum(w) + 1e-12)) * np.sum(w * (rel ** 2)))
    
    # ğŸ”¥ æ–°å¢ï¼šå½¢çŠ¶çº¦æŸï¼ˆå³ä½¿æ•°æ®ç¼ºå¤±ä¹Ÿèƒ½å­¦ä¹ åˆ°åˆç†çš„æ›²çº¿å½¢çŠ¶ï¼‰
    if add_shape_constraint:
        # ç”Ÿæˆè™šæ‹Ÿçš„è†ç›–åŒºåŸŸæ•°æ®ç‚¹ï¼ˆç”¨äºå½¢çŠ¶çº¦æŸï¼‰
        V_oc_est = V_max  # ä¼°è®¡å¼€è·¯ç”µå‹
        knee_low = 0.3 * V_oc_est
        knee_high = 0.7 * V_oc_est
        
        # æ£€æŸ¥è†ç›–åŒºåŸŸæ˜¯å¦æœ‰å®é™…æ•°æ®
        knee_mask_actual = (V_m >= knee_low) & (V_m < knee_high)
        knee_data_count = np.sum(knee_mask_actual)
        
        # ğŸ”¥ å½¢çŠ¶çº¦æŸå·²å¤§å¹…é™ä½ï¼šå…è®¸æ¢ç´¢éæ ‡å‡†å½¢çŠ¶çš„è§£ï¼Œè®©è¯¯å·®å‡½æ•°ä¸»å¯¼ä¼˜åŒ–
        # å¦‚æœè†ç›–åŒºåŸŸæ•°æ®ç‚¹å°‘äº5ä¸ªï¼Œæ·»åŠ å½¢çŠ¶çº¦æŸï¼ˆæƒ©ç½šç³»æ•°å·²é™ä½10å€ï¼‰
        if knee_data_count < 5:
            # ç”Ÿæˆè™šæ‹Ÿè†ç›–åŒºåŸŸç”µå‹ç‚¹
            V_knee_virtual = np.linspace(knee_low, knee_high, 10)
            I_knee_virtual = solar_cell_model(V_knee_virtual, params, I_min, I_max)
            
            # å½¢çŠ¶çº¦æŸ1ï¼šè†ç›–åŒºåŸŸåº”è¯¥æœ‰å¹³æ»‘çš„è¿‡æ¸¡ï¼ˆç”µæµåº”è¯¥å•è°ƒé€’å‡ï¼‰
            I_diff = np.diff(I_knee_virtual)
            # ç”µæµåº”è¯¥éšç”µå‹å¢åŠ è€Œå‡å°‘ï¼ˆI_diffåº”è¯¥ä¸ºè´Ÿï¼‰
            monotonicity_penalty = np.sum(np.maximum(I_diff, 0)) * 0.01  # æƒ©ç½šç³»æ•°ä»0.1é™ä½åˆ°0.01ï¼ˆé™ä½10å€ï¼‰
            
            # å½¢çŠ¶çº¦æŸ2ï¼šè†ç›–åŒºåŸŸçš„ç”µæµåº”è¯¥åœ¨åˆç†èŒƒå›´ï¼ˆI_scçš„30%-90%ï¼‰
            I_sc_est = np.max(I_m)  # ä¼°è®¡çŸ­è·¯ç”µæµ
            I_knee_normalized = I_knee_virtual / (I_sc_est + 1e-12)
            # æƒ©ç½šè¶…å‡ºåˆç†èŒƒå›´çš„éƒ¨åˆ†
            range_penalty = np.sum(np.maximum(I_knee_normalized - 0.95, 0)) * 0.02  # ä»0.2é™ä½åˆ°0.02
            range_penalty += np.sum(np.maximum(0.25 - I_knee_normalized, 0)) * 0.02  # ä»0.2é™ä½åˆ°0.02
            
            # å½¢çŠ¶çº¦æŸ3ï¼šæ›²çº¿åº”è¯¥å¹³æ»‘ï¼ˆäºŒé˜¶å¯¼æ•°ä¸åº”è¯¥å¤ªå¤§ï¼‰
            if len(I_knee_virtual) >= 3:
                I_diff2 = np.diff(I_knee_virtual, n=2)
                smoothness_penalty = np.sum(np.abs(I_diff2)) * 0.005  # ä»0.05é™ä½åˆ°0.005
            
            # æ€»å½¢çŠ¶çº¦æŸæƒ©ç½š
            shape_penalty = monotonicity_penalty + range_penalty + (smoothness_penalty if len(I_knee_virtual) >= 3 else 0)
            loss += shape_penalty
    
    if np.isnan(loss) or np.isinf(loss):
        return 1e10
    return float(loss)


# =============================================================================
# 3. æ›²çº¿ç‰¹å¾æå–ï¼ˆç”¨äºçŠ¶æ€è¡¨ç¤ºï¼‰
# =============================================================================

def extract_curve_features(V: np.ndarray, I_meas: np.ndarray) -> np.ndarray:
    """
    ä» (V, I_meas) æå–å›ºå®šç»´åº¦çš„æ›²çº¿ç‰¹å¾ï¼Œç”¨äºçŠ¶æ€çš„â€œæ›²çº¿éƒ¨åˆ†â€ã€‚
    è¿”å›å‘é‡ï¼šV_oc, I_sc, V_mp, I_mp, fill_factor, V_mean, I_mean, V_std, I_stdï¼ˆä¸å« P_maxï¼Œç”± fill_factor è¡¨å¾ï¼‰
    """
    V_oc = float(np.max(V))
    I_sc = float(np.max(I_meas))
    P = V * I_meas
    P_max = float(np.max(P)) if len(P) > 0 else 0.0
    # æœ€å¤§åŠŸç‡ç‚¹è¿‘ä¼¼ï¼šP æœ€å¤§å¤„çš„ Vã€I
    idx_mp = int(np.argmax(P)) if len(P) > 0 else 0
    V_mp = float(V[idx_mp]) if len(V) > idx_mp else V_oc
    I_mp = float(I_meas[idx_mp]) if len(I_meas) > idx_mp else I_sc
    denom = V_oc * I_sc
    fill_factor = float(P_max / denom) if denom > 1e-20 else 0.0
    V_mean = float(np.mean(V))
    I_mean = float(np.mean(I_meas))
    V_std = float(np.std(V)) if len(V) > 1 else 0.0
    I_std = float(np.std(I_meas)) if len(I_meas) > 1 else 0.0
    feat = np.array(
        [V_oc, I_sc, V_mp, I_mp, fill_factor, V_mean, I_mean, V_std, I_std],
        dtype=np.float64,
    )
    return feat


def normalize_curve_features(feat: np.ndarray, V_oc: float, I_sc: float) -> np.ndarray:
    """
    æ”¹è¿›ï¼šä½¿ç”¨æ›´é²æ£’çš„å½’ä¸€åŒ–æ–¹æ³•ï¼Œæå‡å¯¹ä¸åŒæ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ã€‚
    ç”¨ V_ocã€I_sc ç­‰åšå½’ä¸€åŒ–ï¼Œé¿å…æ•°å€¼å°ºåº¦è¿‡å¤§ã€‚
    feat ä¸º 9 ç»´ï¼šV_oc, I_sc, V_mp, I_mp, fill_factor, V_mean, I_mean, V_std, I_stdã€‚
    """
    out = feat.copy()
    # ä½¿ç”¨æ›´é²æ£’çš„å½’ä¸€åŒ–ï¼šé¿å…é™¤é›¶ï¼Œä½¿ç”¨å¹³æ»‘å› å­
    eps = 1e-12
    
    if V_oc > eps:
        out[0] = feat[0] / V_oc   # V_oc -> 1.0
        out[2] = feat[2] / V_oc   # V_mp -> [0, 1]
        out[5] = feat[5] / V_oc   # V_mean -> [0, 1]
        # V_std å½’ä¸€åŒ–ï¼šé™¤ä»¥ V_ocï¼Œæ”¾å®½èŒƒå›´é¿å…è£å‰ªæœ‰æ•ˆæ•°æ®
        out[7] = np.clip(feat[7] / (V_oc + eps), 0.0, 3.0)  # V_std -> [0, 3]ï¼Œä»1.0æ”¾å®½åˆ°3.0
    else:
        # å¦‚æœ V_oc å¤ªå°ï¼Œä½¿ç”¨å›ºå®šå½’ä¸€åŒ–
        out[0] = 1.0
        out[2] = 0.5
        out[5] = 0.5
        out[7] = 0.1
    
    if I_sc > eps:
        out[1] = feat[1] / I_sc   # I_sc -> 1.0
        out[3] = feat[3] / I_sc   # I_mp -> [0, 1]
        out[6] = feat[6] / I_sc   # I_mean -> [0, 1]
        # I_std å½’ä¸€åŒ–ï¼šé™¤ä»¥ I_scï¼Œæ”¾å®½èŒƒå›´é¿å…è£å‰ªæœ‰æ•ˆæ•°æ®
        out[8] = np.clip(feat[8] / (I_sc + eps), 0.0, 3.0)  # I_std -> [0, 3]ï¼Œä»1.0æ”¾å®½åˆ°3.0
    else:
        # å¦‚æœ I_sc å¤ªå°ï¼Œä½¿ç”¨å›ºå®šå½’ä¸€åŒ–
        out[1] = 1.0
        out[3] = 0.5
        out[6] = 0.5
        out[8] = 0.1
    
    # out[4] ä¸º fill_factorï¼Œæ”¾å®½èŒƒå›´é¿å…è£å‰ªæœ‰æ•ˆæ•°æ®ï¼ˆç†è®ºä¸Šåœ¨[0,1]ï¼Œä½†å¼‚å¸¸æ•°æ®å¯èƒ½è¶…å‡ºï¼‰
    out[4] = np.clip(feat[4], 0.0, 1.5)  # fill_factor -> [0, 1.5]ï¼Œä»1.0æ”¾å®½åˆ°1.5
    
    return out.astype(np.float32)


# =============================================================================
# 4. å‚æ•°è¾¹ç•Œã€å†…éƒ¨è¡¨ç¤ºï¼ˆI0 ç”¨ log10ï¼‰ã€æ˜ å°„ä¸å¢é‡èŒƒå›´
# =============================================================================

# ğŸ”¥ åŒäºŒæç®¡æ¨¡å‹å‚æ•°è¾¹ç•Œ [I_ph, I01, I02, n1, n2, Rs, Rsh]
# åŒäºŒæç®¡æ¨¡å‹å¯ä»¥æè¿°ä¸¤ç§å¤åˆæœºåˆ¶ï¼Œé€šå¸¸èƒ½æ›´å¥½åœ°æ‹Ÿåˆå®é™…æ•°æ®
# ğŸ”¥ å¤§å¹…æ‰©å¤§è¾¹ç•Œï¼šæ ¹æ®å®é™…æ‹Ÿåˆç»“æœï¼Œæœ€ä¼˜å‚æ•°å¯èƒ½åœ¨è¾¹ç•Œé™„è¿‘ï¼Œéœ€è¦æ›´å¤§æœç´¢ç©ºé—´
DEFAULT_PARAM_BOUNDS = np.array([
    [0.1, 30.0],       # I_phï¼ˆå…‰ç”Ÿç”µæµï¼Œä¸Šç•Œä»25.0æ‰©å¤§åˆ°30.0ï¼Œç»™æ›´å¤šæ¢ç´¢ç©ºé—´ï¼‰
    [1e-60, 100.0],    # I01ï¼ˆç¬¬ä¸€ä¸ªäºŒæç®¡çš„é¥±å’Œç”µæµï¼Œç‰©ç†å€¼ä¸Šç•Œä»10.0æ‰©å¤§åˆ°100.0ï¼‰
                       # log10ç©ºé—´ä¸Šç•Œ = log10(100.0) â‰ˆ 2.0ï¼Œç»™æ›´å¤šæ¢ç´¢ç©ºé—´
    [1e-60, 100.0],    # I02ï¼ˆç¬¬äºŒä¸ªäºŒæç®¡çš„é¥±å’Œç”µæµï¼Œç‰©ç†å€¼ä¸Šç•Œä»10.0æ‰©å¤§åˆ°100.0ï¼‰â­å…³é”®ä¿®å¤
                       # log10ç©ºé—´ä¸Šç•Œ = log10(100.0) â‰ˆ 2.0ï¼Œè§£å†³I02å¡åœ¨è¾¹ç•Œçš„é—®é¢˜
    [1.0, 3.5],        # n1ï¼ˆç¬¬ä¸€ä¸ªäºŒæç®¡çš„ç†æƒ³å› å­ï¼Œä¸Šç•Œä»3.0æ‰©å¤§åˆ°3.5ï¼‰
    [1.5, 10.0],       # n2ï¼ˆç¬¬äºŒä¸ªäºŒæç®¡çš„ç†æƒ³å› å­ï¼Œä¸Šç•Œä»6.0æ‰©å¤§åˆ°10.0ï¼‰â­å…³é”®ä¿®å¤
                       # è§£å†³n2å¡åœ¨è¾¹ç•Œçš„é—®é¢˜ï¼Œç»™æ›´å¤šæ¢ç´¢ç©ºé—´
    [0.001, 3.0],      # Rsï¼ˆä¸²è”ç”µé˜»ï¼Œä¸Šç•Œä»2.0æ‰©å¤§åˆ°3.0ï¼‰
    [10.0, 1000.0],    # Rshï¼ˆå¹¶è”ç”µé˜»ï¼Œä¸Šç•Œä»500.0æ‰©å¤§åˆ°1000.0ï¼‰
], dtype=np.float64)

# å†…éƒ¨è¡¨ç¤ºï¼šp = [I_ph, log10(I01), log10(I02), n1, n2, Rs, Rsh]
I01_IDX = 1  # I01åœ¨log10ç©ºé—´
I02_IDX = 2  # I02åœ¨log10ç©ºé—´


def internal_to_params(internal: np.ndarray, bounds: np.ndarray) -> np.ndarray:
    """å†…éƒ¨è¡¨ç¤º -> ç‰©ç†å‚æ•°ï¼ˆç”¨äº solar_cell_model / objectiveï¼‰ã€‚"""
    x = internal.copy()
    # åŒäºŒæç®¡æ¨¡å‹ï¼šI01å’ŒI02éƒ½åœ¨log10ç©ºé—´
    if len(x) == 7:
        x[I01_IDX] = 10.0 ** float(x[I01_IDX])
        x[I02_IDX] = 10.0 ** float(x[I02_IDX])
    else:
        # å‘åå…¼å®¹ï¼šå•äºŒæç®¡æ¨¡å‹
        x[I01_IDX] = 10.0 ** float(x[I01_IDX])
    return x


def clip_params_to_bounds(internal: np.ndarray, bounds: np.ndarray) -> np.ndarray:
    """å°†å†…éƒ¨è¡¨ç¤ºè£å‰ªåˆ°è¾¹ç•Œå†…ã€‚"""
    out = internal.copy()
    if len(out) == 7:
        # åŒäºŒæç®¡æ¨¡å‹ï¼š7ä¸ªå‚æ•°
        out[0] = np.clip(out[0], bounds[0, 0], bounds[0, 1])  # I_ph
        out[I01_IDX] = np.clip(out[I01_IDX], np.log10(bounds[I01_IDX, 0]), np.log10(bounds[I01_IDX, 1]))  # log10(I01)
        out[I02_IDX] = np.clip(out[I02_IDX], np.log10(bounds[I02_IDX, 0]), np.log10(bounds[I02_IDX, 1]))  # log10(I02)
        out[3] = np.clip(out[3], bounds[3, 0], bounds[3, 1])  # n1
        out[4] = np.clip(out[4], bounds[4, 0], bounds[4, 1])  # n2
        out[5] = np.clip(out[5], bounds[5, 0], bounds[5, 1])  # Rs
        out[6] = np.clip(out[6], bounds[6, 0], bounds[6, 1])  # Rsh
    else:
        # å‘åå…¼å®¹ï¼šå•äºŒæç®¡æ¨¡å‹
        out[0] = np.clip(out[0], bounds[0, 0], bounds[0, 1])
        out[I01_IDX] = np.clip(out[I01_IDX], np.log10(bounds[I01_IDX, 0]), np.log10(bounds[I01_IDX, 1]))
        out[2] = np.clip(out[2], bounds[2, 0], bounds[2, 1])
        out[3] = np.clip(out[3], bounds[3, 0], bounds[3, 1])
        out[4] = np.clip(out[4], bounds[4, 0], bounds[4, 1])
    return out


def clip_params_to_bounds_trainable(internal: np.ndarray, bounds: np.ndarray) -> np.ndarray:
    """å°†5ä¸ªå¯è®­ç»ƒå‚æ•°è£å‰ªåˆ°è¾¹ç•Œå†…ï¼ˆå›ºå®šn1å’Œn2æ¨¡å¼ï¼‰ã€‚"""
    out = internal.copy()
    # 5ä¸ªå‚æ•°ï¼š[I_ph, log10(I01), log10(I02), Rs, Rsh]
    out[0] = np.clip(out[0], bounds[0, 0], bounds[0, 1])  # I_ph
    out[I01_IDX] = np.clip(out[I01_IDX], np.log10(bounds[I01_IDX, 0]), np.log10(bounds[I01_IDX, 1]))  # log10(I01)
    out[I02_IDX] = np.clip(out[I02_IDX], np.log10(bounds[I02_IDX, 0]), np.log10(bounds[I02_IDX, 1]))  # log10(I02)
    out[3] = np.clip(out[3], bounds[5, 0], bounds[5, 1])  # Rs (ä½¿ç”¨bounds[5])
    out[4] = np.clip(out[4], bounds[6, 0], bounds[6, 1])  # Rsh (ä½¿ç”¨bounds[6])
    return out


def internal_to_normalized(internal: np.ndarray, bounds: np.ndarray) -> np.ndarray:
    """å†…éƒ¨å‚æ•°æ˜ å°„åˆ° [0,1]ï¼Œä¾¿äºç½‘ç»œè¾“å…¥ã€‚"""
    if len(internal) == 7:
        # åŒäºŒæç®¡æ¨¡å‹ï¼š7ä¸ªå‚æ•°
        n = np.zeros(7, dtype=np.float32)
        n[0] = (internal[0] - bounds[0, 0]) / (bounds[0, 1] - bounds[0, 0] + 1e-12)  # I_ph
        log_lo1 = np.log10(bounds[I01_IDX, 0])
        log_hi1 = np.log10(bounds[I01_IDX, 1])
        n[I01_IDX] = (internal[I01_IDX] - log_lo1) / (log_hi1 - log_lo1 + 1e-12)  # log10(I01)
        log_lo2 = np.log10(bounds[I02_IDX, 0])
        log_hi2 = np.log10(bounds[I02_IDX, 1])
        n[I02_IDX] = (internal[I02_IDX] - log_lo2) / (log_hi2 - log_lo2 + 1e-12)  # log10(I02)
        n[3] = (internal[3] - bounds[3, 0]) / (bounds[3, 1] - bounds[3, 0] + 1e-12)  # n1
        n[4] = (internal[4] - bounds[4, 0]) / (bounds[4, 1] - bounds[4, 0] + 1e-12)  # n2
        n[5] = (internal[5] - bounds[5, 0]) / (bounds[5, 1] - bounds[5, 0] + 1e-12)  # Rs
        n[6] = (internal[6] - bounds[6, 0]) / (bounds[6, 1] - bounds[6, 0] + 1e-12)  # Rsh
    else:
        # å‘åå…¼å®¹ï¼šå•äºŒæç®¡æ¨¡å‹
        n = np.zeros(5, dtype=np.float32)
        n[0] = (internal[0] - bounds[0, 0]) / (bounds[0, 1] - bounds[0, 0] + 1e-12)
        log_lo = np.log10(bounds[I01_IDX, 0])
        log_hi = np.log10(bounds[I01_IDX, 1])
        n[I01_IDX] = (internal[I01_IDX] - log_lo) / (log_hi - log_lo + 1e-12)
        n[2] = (internal[2] - bounds[2, 0]) / (bounds[2, 1] - bounds[2, 0] + 1e-12)
        n[3] = (internal[3] - bounds[3, 0]) / (bounds[3, 1] - bounds[3, 0] + 1e-12)
        n[4] = (internal[4] - bounds[4, 0]) / (bounds[4, 1] - bounds[4, 0] + 1e-12)
    return np.clip(n, 0.0, 1.0)


# æ¯ç»´å¢é‡çš„æœ€å¤§ç»å¯¹å€¼ï¼ˆä¸å†…éƒ¨è¡¨ç¤ºä¸€è‡´ï¼›I01å’ŒI02ä¸ºlog10ç©ºé—´ï¼‰
# åŒäºŒæç®¡æ¨¡å‹ï¼š7ä¸ªå‚æ•°
DEFAULT_MAX_DELTA = np.array([0.5, 1.0, 1.0, 0.02, 0.02, 0.02, 10.0], dtype=np.float64)
# å•äºŒæç®¡æ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
DEFAULT_MAX_DELTA_SINGLE = np.array([0.5, 1.0, 0.02, 0.02, 10.0], dtype=np.float64)


# =============================================================================
# å‚æ•°è®¿é—®è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€ç®¡ç†å‚æ•°ç´¢å¼•ï¼Œæ¶ˆé™¤é‡å¤ä»£ç 
# =============================================================================

class ParamAccessor:
    """å‚æ•°è®¿é—®å™¨ï¼šç»Ÿä¸€ç®¡ç†å•/åŒäºŒæç®¡æ¨¡å‹çš„å‚æ•°ç´¢å¼•"""
    
    @staticmethod
    def is_double_diode(params: np.ndarray) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŒäºŒæç®¡æ¨¡å‹"""
        return len(params) == 7
    
    @staticmethod
    def get_param_indices(is_double: bool) -> Dict[str, int]:
        """è·å–å‚æ•°ç´¢å¼•å­—å…¸"""
        if is_double:
            return {
                'I_ph': 0, 'I01': 1, 'I02': 2, 'n1': 3, 'n2': 4, 'Rs': 5, 'Rsh': 6
            }
        else:
            return {
                'I_ph': 0, 'I0': 1, 'n': 2, 'Rs': 3, 'Rsh': 4
            }
    
    @staticmethod
    def get_param(params: np.ndarray, param_name: str) -> float:
        """ç»Ÿä¸€è·å–å‚æ•°å€¼"""
        is_double = ParamAccessor.is_double_diode(params)
        indices = ParamAccessor.get_param_indices(is_double)
        if param_name not in indices:
            raise ValueError(f"Unknown parameter: {param_name}")
        return params[indices[param_name]]
    
    @staticmethod
    def get_I0_total(params: np.ndarray) -> float:
        """è·å–æ€»é¥±å’Œç”µæµï¼ˆI0æˆ–I01+I02ï¼‰"""
        if ParamAccessor.is_double_diode(params):
            return params[1] + params[2]  # I01 + I02
        else:
            return params[1]  # I0


# =============================================================================
# 5. Actor / Critic ç½‘ç»œ
# =============================================================================

class Actor(nn.Module):
    """
    Actorï¼šè¾“å…¥çŠ¶æ€ sï¼Œè¾“å‡ºå‚æ•°å¢é‡ Î”p çš„å‡å€¼ï¼›
    æ¢ç´¢æ—¶ä½¿ç”¨é«˜æ–¯å™ªå£°ï¼Œlog_std å¯å­¦ä¹ æˆ–å›ºå®šã€‚
    æ”¹è¿›ï¼šæ›´æ·±ç½‘ç»œ + LayerNorm + æ®‹å·®è¿æ¥ï¼Œæå‡è¡¨è¾¾èƒ½åŠ›ã€‚
    """

    def __init__(
        self,
        state_dim: int,
        action_dim: int = 5,
        hidden: int = 384,  # å¢å¤§éšè—å±‚ï¼š256 -> 384ï¼Œè¿›ä¸€æ­¥æå‡ç½‘ç»œå®¹é‡
        log_std_init: float = -0.1,  # è¿›ä¸€æ­¥å¢å¤§åˆå§‹æ¢ç´¢ï¼š-0.3 -> -0.1ï¼Œé¼“åŠ±æ›´å¤šæ¢ç´¢
    ):
        super().__init__()
        self.action_dim = action_dim
        self.log_std_init = log_std_init
        # æ›´æ·±ç½‘ç»œï¼š3å±‚éšè—å±‚ï¼Œæå‡è¡¨è¾¾èƒ½åŠ›
        self.fc1 = nn.Linear(state_dim, hidden)
        self.ln1 = nn.LayerNorm(hidden)  # LayerNorm ç¨³å®šè®­ç»ƒ
        self.fc2 = nn.Linear(hidden, hidden)
        self.ln2 = nn.LayerNorm(hidden)
        self.fc3 = nn.Linear(hidden, hidden // 2)  # ç¬¬ä¸‰å±‚
        self.ln3 = nn.LayerNorm(hidden // 2)
        self.fc4 = nn.Linear(hidden // 2, action_dim)
        self.log_std = nn.Parameter(torch.full((action_dim,), log_std_init))

    def forward(self, s: torch.Tensor, exploration_factor: float = 1.0) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ”¹è¿›ï¼šæ·»åŠ è‡ªé€‚åº”æ¢ç´¢å› å­ï¼Œæ ¹æ®è®­ç»ƒè¿›åº¦è°ƒæ•´æ¢ç´¢èŒƒå›´ã€‚
        exploration_factor: æ¢ç´¢å› å­ï¼Œ1.0è¡¨ç¤ºå®Œå…¨æ¢ç´¢ï¼Œ0.3è¡¨ç¤ºæœ€å°æ¢ç´¢
        """
        # æ›´æ·±ç½‘ç»œ + LayerNorm + æ®‹å·®è¿æ¥
        x = F.relu(self.ln1(self.fc1(s)))
        x = F.relu(self.ln2(self.fc2(x))) + x  # æ®‹å·®è¿æ¥ï¼ˆfc1 å’Œ fc2 ç»´åº¦ç›¸åŒï¼‰
        x = F.relu(self.ln3(self.fc3(x)))  # fc3 ç»´åº¦ä¸åŒï¼Œä¸åšæ®‹å·®è¿æ¥
        mean = self.fc4(x)
        # æ”¹è¿›ï¼šè‡ªé€‚åº”æ¢ç´¢ï¼Œæ ¹æ®è®­ç»ƒè¿›åº¦è°ƒæ•´log_stdèŒƒå›´
        # exploration_factorä»1.0ï¼ˆåˆæœŸï¼‰è¡°å‡åˆ°0.3ï¼ˆåæœŸï¼‰
        log_std_base = self.log_std.clamp(-1.2, 1.0)  # åŸºç¡€èŒƒå›´
        # åº”ç”¨æ¢ç´¢å› å­ï¼šåˆæœŸæ¢ç´¢å¤§ï¼ŒåæœŸæ¢ç´¢å°
        log_std_adjusted = log_std_base * exploration_factor
        std = log_std_adjusted.exp()
        return mean, std

    def sample(self, s: torch.Tensor, exploration_factor: float = 1.0) -> Tuple[torch.Tensor, torch.Tensor]:
        mean, std = self.forward(s, exploration_factor)
        dist = torch.distributions.Normal(mean, std + 1e-6)
        a = dist.rsample()
        log_prob = dist.log_prob(a).sum(dim=-1)
        return a, log_prob

    def log_prob(self, s: torch.Tensor, a: torch.Tensor, exploration_factor: float = 1.0) -> torch.Tensor:
        mean, std = self.forward(s, exploration_factor)
        dist = torch.distributions.Normal(mean, std + 1e-6)
        return dist.log_prob(a).sum(dim=-1)


class Critic(nn.Module):
    """Criticï¼šè¾“å…¥çŠ¶æ€ sï¼Œè¾“å‡ºæ ‡é‡ V(s)ã€‚æ”¹è¿›ï¼šæ›´æ·±ç½‘ç»œ + LayerNormï¼Œæå‡ä»·å€¼ä¼°è®¡å‡†ç¡®æ€§ã€‚"""

    def __init__(self, state_dim: int, hidden: int = 384):  # å¢å¤§éšè—å±‚ï¼š256 -> 384ï¼Œè¿›ä¸€æ­¥æå‡ç½‘ç»œå®¹é‡
        super().__init__()
        self.fc1 = nn.Linear(state_dim, hidden)
        self.ln1 = nn.LayerNorm(hidden)
        self.fc2 = nn.Linear(hidden, hidden)
        self.ln2 = nn.LayerNorm(hidden)
        self.fc3 = nn.Linear(hidden, hidden // 2)  # ç¬¬ä¸‰å±‚
        self.ln3 = nn.LayerNorm(hidden // 2)
        self.fc4 = nn.Linear(hidden // 2, 1)

    def forward(self, s: torch.Tensor) -> torch.Tensor:
        x = F.relu(self.ln1(self.fc1(s)))
        x = F.relu(self.ln2(self.fc2(x))) + x  # æ®‹å·®è¿æ¥ï¼ˆfc1 å’Œ fc2 ç»´åº¦ç›¸åŒï¼‰
        x = F.relu(self.ln3(self.fc3(x)))  # fc3 ç»´åº¦ä¸åŒï¼Œä¸åšæ®‹å·®è¿æ¥
        return self.fc4(x).squeeze(-1)


# =============================================================================
# 6. æ–¹æ¡ˆ B ç¯å¢ƒä¸è®­ç»ƒé€»è¾‘
# =============================================================================

class ACSolarFitter:
    """
    æ–¹æ¡ˆ Bï¼šå¤šæ­¥è¿­ä»£ Actor-Critic æ‹Ÿåˆå™¨ã€‚
    æ¯æ¡æ›²çº¿ä¸€ä¸ª episodeï¼Œå¤šæ­¥æ›´æ–°å‚æ•°ï¼Œç”¨ r_t = f(p_t) - f(p_{t+1}) åšå¥–åŠ±ã€‚
    """

    def __init__(
        self,
        V: np.ndarray,
        I_meas: np.ndarray,
        I_min: float,
        I_max: float,
        *,
        param_bounds: Optional[np.ndarray] = None,
        T_max: int = 30,
        gamma: float = 0.995,  # ğŸ”¥ æé«˜æŠ˜æ‰£å› å­ï¼šä»0.99åˆ°0.995ï¼Œå‡å°‘çŸ­è§†ï¼Œæ›´å…³æ³¨é•¿æœŸä¼˜åŒ–
        alpha: float = TrainingConfig.DEFAULT_ALPHA,
        max_delta: Optional[np.ndarray] = None,
        lr_actor: float = 1.5e-4,  # ğŸ”¥ å°å¹…æé«˜é»˜è®¤å­¦ä¹ ç‡ï¼šä»1e-4æé«˜åˆ°1.5e-4ï¼ˆ+50%ï¼‰ï¼Œä¿å®ˆè°ƒæ•´
        lr_critic: float = 2.5e-4,  # ğŸ”¥ å°å¹…æé«˜é»˜è®¤å­¦ä¹ ç‡ï¼šä»2e-4æé«˜åˆ°2.5e-4ï¼ˆ+25%ï¼‰ï¼Œä¿å®ˆè°ƒæ•´
        device: Optional[torch.device] = None,
    ):
        self.V = np.asarray(V, dtype=np.float64)
        self.I_meas = np.asarray(I_meas, dtype=np.float64)
        self.I_min = float(I_min)
        self.I_max = float(I_max)
        
        # å…ˆæå–æ›²çº¿ç‰¹å¾ï¼Œç”¨äºåç»­çš„è‡ªé€‚åº”è¾¹ç•Œè®¾ç½®
        self._curve_feat = extract_curve_features(self.V, self.I_meas)
        
        # I_ph åº”æ¥è¿‘ I_scï¼Œç”¨æ›²çº¿ç‰¹å¾çº¦æŸ I_ph è¾¹ç•Œï¼Œé¿å…æ•´æ¡æ‹Ÿåˆè¢«å‹åˆ°ä½ä½
        I_sc = float(np.max(I_meas)) if len(I_meas) > 0 else 1.0
        V_oc = float(np.max(V)) if len(V) > 0 else 1.0
        bounds = np.asarray(param_bounds if param_bounds is not None else DEFAULT_PARAM_BOUNDS, dtype=np.float64)
        bounds = bounds.copy()
        
        # æ”¹è¿›ï¼šè‡ªé€‚åº”å‚æ•°è¾¹ç•Œï¼Œæ ¹æ®æ•°æ®ç‰¹å¾åŠ¨æ€è°ƒæ•´ï¼Œæå‡å¯¹ä¸åŒæ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›
        # I_ph è¾¹ç•Œï¼šåŸºäº I_scï¼Œä½†å…è®¸æ›´å¤§èŒƒå›´ä»¥é€‚åº”ä¸åŒæ•°æ®é›†ï¼ˆè¿›ä¸€æ­¥æ”¾å®½ï¼‰
        bounds[0, 0] = max(bounds[0, 0], I_sc * 0.7)   # ä» 0.85 è¿›ä¸€æ­¥æ”¾å®½åˆ° 0.7ï¼Œç»™æ›´å¤šæ¢ç´¢ç©ºé—´
        bounds[0, 1] = max(bounds[0, 1], I_sc * 1.5)   # ä» 1.25 è¿›ä¸€æ­¥æ”¾å®½åˆ° 1.5ï¼Œç»™ä¼˜åŒ–å™¨æ›´å¤§ç©ºé—´
        
        # I0 è¾¹ç•Œï¼šæ ¹æ® V_oc å’Œ I_sc è‡ªé€‚åº”è°ƒæ•´
        # å¯¹äºé«˜ç”µå‹ç”µæ± ï¼ŒI0 éœ€è¦æ›´å¤§çš„ä¸Šç•Œï¼ˆä¿®å¤ï¼šä½¿ç”¨maxè€Œä¸æ˜¯minï¼‰
        if V_oc > 50.0:
            bounds[1, 1] = max(bounds[1, 1], 1e-6)  # é«˜ç”µå‹ç”µæ± ï¼šä»1e-7æé«˜åˆ°1e-6ï¼Œä½¿ç”¨maxç¡®ä¿æ”¾å®½
        elif V_oc > 30.0:
            bounds[1, 1] = max(bounds[1, 1], 1e-7)  # ä¸­ç­‰ç”µå‹ç”µæ± ï¼šæ”¾å®½åˆ°1e-7
        
        # n è¾¹ç•Œï¼šæ ¹æ®æ›²çº¿ç‰¹å¾è‡ªé€‚åº”è°ƒæ•´ï¼ˆä¿®å¤ï¼šæ”¾å®½nçš„ä¸‹ç•Œå’Œä¸Šç•Œï¼‰
        fill_factor = self._curve_feat[4] if len(self._curve_feat) > 4 else 0.7
        # æ”¾å®½nçš„ä¸‹ç•Œï¼Œå…è®¸æ›´å°çš„nï¼ˆæŸäº›ç”µæ± å¯èƒ½éœ€è¦ï¼‰
        bounds[2, 0] = max(bounds[2, 0], 0.8)  # nä¸‹ç•Œä»1.0æ”¾å®½åˆ°0.8
        if fill_factor < 0.6:
            bounds[2, 1] = max(bounds[2, 1], 2.5)  # ä½å¡«å……å› å­ï¼šä½¿ç”¨maxç¡®ä¿æ”¾å®½åˆ°2.5
        else:
            bounds[2, 1] = max(bounds[2, 1], 2.5)  # æ‰€æœ‰æƒ…å†µéƒ½æ”¾å®½åˆ°2.5ï¼Œæå‡æ¨¡å‹è¡¨è¾¾èƒ½åŠ›
        
        # Rs è¾¹ç•Œï¼šæ ¹æ® I_sc è‡ªé€‚åº”è°ƒæ•´ï¼ˆå¤§ç”µæµç”µæ± éœ€è¦æ›´å¤§çš„ Rsï¼Œä¿®å¤ï¼šä½¿ç”¨maxç¡®ä¿æ”¾å®½ï¼‰
        if I_sc > 10.0:
            bounds[3, 1] = max(bounds[3, 1], 1.0)  # å¤§ç”µæµç”µæ± ï¼šä»0.8æé«˜åˆ°1.0ï¼Œä½¿ç”¨maxç¡®ä¿æ”¾å®½
        elif I_sc > 5.0:
            bounds[3, 1] = max(bounds[3, 1], 0.8)  # ä¸­ç­‰ç”µæµç”µæ± ï¼šæ”¾å®½åˆ°0.8
        else:
            bounds[3, 1] = max(bounds[3, 1], 0.6)  # å°ç”µæµç”µæ± ï¼šæ”¾å®½åˆ°0.6
        
        # Rsh è¾¹ç•Œï¼šæ ¹æ® I_sc å’Œ V_oc è‡ªé€‚åº”è°ƒæ•´
        if I_sc > 10.0 or V_oc > 50.0:
            bounds[4, 0] = max(bounds[4, 0], 10.0)  # å¤§ç”µæµæˆ–é«˜ç”µå‹ç”µæ± å…è®¸æ›´å°çš„ Rsh
            bounds[4, 1] = min(bounds[4, 1], 300.0)  # å…è®¸æ›´å¤§çš„ Rsh
        
        self.param_bounds = bounds
        
        # ğŸ”¥ å›ºå®šn1å’Œn2ï¼šå¦‚æœå›ºå®šï¼Œåªè®­ç»ƒ5ä¸ªå‚æ•°ï¼ˆI_ph, I01, I02, Rs, Rshï¼‰
        # å¿…é¡»åœ¨è®¾ç½®max_deltaä¹‹å‰è®¾ç½®ï¼Œå› ä¸ºmax_deltaçš„ç»´åº¦ä¾èµ–äºè¿™ä¸ªè®¾ç½®
        self.fix_n1 = TrainingConfig.FIX_N1
        self.fix_n2 = TrainingConfig.FIX_N2
        self.fixed_n1 = TrainingConfig.FIXED_N1_VALUE
        self.fixed_n2 = TrainingConfig.FIXED_N2_VALUE
        
        self.T_max = T_max
        self.gamma = gamma
        self.alpha = alpha
        
        # ğŸ”¥ æ ¹æ®æ˜¯å¦å›ºå®šn1å’Œn2ï¼Œè°ƒæ•´max_deltaçš„ç»´åº¦
        if self.fix_n1 and self.fix_n2:
            # å›ºå®šæ¨¡å¼ï¼šåªè®­ç»ƒ5ä¸ªå‚æ•°ï¼Œmax_deltaä¹Ÿåº”è¯¥æ˜¯5ä¸ªå…ƒç´ 
            # å¯¹åº” [I_ph, I01, I02, Rs, Rsh] çš„max_delta
            if max_delta is None:
                # ä»7å‚æ•°max_deltaä¸­æå–5ä¸ªå‚æ•°å¯¹åº”çš„å€¼
                default_7 = DEFAULT_MAX_DELTA
                self.max_delta = np.array([
                    default_7[0],      # I_ph: 0.5
                    default_7[1],      # I01: 1.0 (log10ç©ºé—´)
                    default_7[2],      # I02: 1.0 (log10ç©ºé—´)
                    default_7[5],      # Rs: 0.02 (åŸç´¢å¼•5)
                    default_7[6],      # Rsh: 10.0 (åŸç´¢å¼•6)
                ], dtype=np.float64)
            else:
                # å¦‚æœç”¨æˆ·æä¾›äº†max_deltaï¼Œç¡®ä¿å®ƒæ˜¯5ä¸ªå…ƒç´ 
                if len(max_delta) == 5:
                    self.max_delta = np.asarray(max_delta, dtype=np.float64)
                else:
                    raise ValueError(f"å›ºå®šn1å’Œn2æ¨¡å¼ä¸‹ï¼Œmax_deltaåº”è¯¥æ˜¯5ä¸ªå…ƒç´ ï¼Œä½†å¾—åˆ°{len(max_delta)}ä¸ª")
        else:
            # å®Œæ•´æ¨¡å¼ï¼š7ä¸ªå‚æ•°
            self.max_delta = np.asarray(max_delta if max_delta is not None else DEFAULT_MAX_DELTA, dtype=np.float64)
        # ğŸ”¥ æ”¹è¿›GPUæ£€æµ‹ï¼šæ›´å¯é çš„CUDAåˆå§‹åŒ–
        if device is not None:
            self.device = device
        else:
            # å°è¯•åˆå§‹åŒ–CUDA
            try:
                if torch.cuda.is_available():
                    # æµ‹è¯•GPUæ˜¯å¦çœŸçš„å¯ç”¨ï¼ˆé¿å…è™šå‡çš„is_available()ï¼‰
                    test_tensor = torch.tensor([1.0]).cuda()
                    self.device = torch.device("cuda")
                    del test_tensor
                    torch.cuda.empty_cache()
                else:
                    self.device = torch.device("cpu")
            except Exception as e:
                # å¦‚æœCUDAåˆå§‹åŒ–å¤±è´¥ï¼Œfallbackåˆ°CPU
                print(f"âš  CUDAåˆå§‹åŒ–å¤±è´¥: {e}")
                print("   å°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆä¼šå¾ˆæ…¢ï¼‰")
                self.device = torch.device("cpu")

        # æ›²çº¿ç‰¹å¾å½’ä¸€åŒ–ï¼ˆä½¿ç”¨å·²æå–çš„ç‰¹å¾ï¼‰
        self._curve_feat_norm = normalize_curve_features(
            self._curve_feat,
            self._curve_feat[0],
            self._curve_feat[1],
        )
        # ğŸ”¥ åŒäºŒæç®¡æ¨¡å‹ï¼šparams_normä»5å˜æˆ7
        # è®¡ç®—å®é™…éœ€è¦è®­ç»ƒçš„å‚æ•°æ•°é‡ï¼ˆfix_n1å’Œfix_n2å·²åœ¨ä¸Šé¢è®¾ç½®ï¼‰
        if self.fix_n1 and self.fix_n2:
            self.trainable_param_count = 5  # I_ph, I01, I02, Rs, Rsh
            self._state_dim = 9 + 5 + 1 + 1 + 1  # curve(9) + params_norm(5) + log(1+f) + delta_f_norm + t/T
            print(f"ğŸ”§ å›ºå®šå‚æ•°æ¨¡å¼ï¼šn1={self.fixed_n1}, n2={self.fixed_n2}ï¼Œåªè®­ç»ƒ5ä¸ªå‚æ•°")
        else:
            self.trainable_param_count = 7  # æ‰€æœ‰7ä¸ªå‚æ•°
            self._state_dim = 9 + 7 + 1 + 1 + 1  # curve(9) + params_norm(7) + log(1+f) + delta_f_norm + t/T
        
        # Actorå’ŒCriticç½‘ç»œï¼šæ ¹æ®æ˜¯å¦å›ºå®šå‚æ•°è°ƒæ•´ç»´åº¦
        self.actor = Actor(self._state_dim, action_dim=self.trainable_param_count, hidden=384).to(self.device)
        self.critic = Critic(self._state_dim, hidden=384).to(self.device)  # ä»256å¢åŠ åˆ°384ï¼Œæå‡ç½‘ç»œå®¹é‡
        # å­¦ä¹ ç‡é…ç½®ï¼ˆä½¿ç”¨é…ç½®ç±»ï¼‰
        is_double_diode = len(self.param_bounds) == 7
        lr_multiplier = TrainingConfig.LR_MULTIPLIER_DOUBLE_DIODE if is_double_diode else 1.0
        lr_actor_actual = lr_actor * lr_multiplier
        lr_critic_actual = lr_critic * lr_multiplier
        self.opt_actor = optim.Adam(self.actor.parameters(), lr=lr_actor_actual, weight_decay=1e-5)
        self.opt_critic = optim.Adam(self.critic.parameters(), lr=lr_critic_actual, weight_decay=1e-5)
        # æ·»åŠ å­¦ä¹ ç‡è¡°å‡è°ƒåº¦å™¨ï¼Œæ¯100è½®è¡°å‡10%ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§
        self.scheduler_actor = optim.lr_scheduler.StepLR(self.opt_actor, step_size=100, gamma=0.9)
        self.scheduler_critic = optim.lr_scheduler.StepLR(self.opt_critic, step_size=100, gamma=0.9)
        
        # ========== æ–°å¢ï¼šè‡ªé€‚åº”æƒé‡è°ƒæ•´ç³»ç»Ÿ ==========
        # ç”¨äºè·Ÿè¸ªä¸åŒå¥–åŠ±çš„å†å²è¡¨ç°ï¼Œè‡ªåŠ¨è°ƒæ•´æƒé‡
        self.reward_history = {
            'sparse': [],  # ç¨€ç–å¥–åŠ±å†å²
            'flat': [],    # I_phå¥–åŠ±å†å²
            'knee': [],    # I0å¥–åŠ±å†å²
            'rs': [],      # Rså¥–åŠ±å†å²
            'rsh': [],     # Rshå¥–åŠ±å†å²
            'boundary': [] # ğŸ”¥ è¾¹ç•Œæƒ©ç½šå¥–åŠ±å†å²
        }
        # è‡ªé€‚åº”æƒé‡ï¼ˆåˆå§‹å€¼ï¼Œä½¿ç”¨é…ç½®ç±»ï¼‰
        self.adaptive_weights = TrainingConfig.REWARD_WEIGHTS.copy()
        # å¥–åŠ±å½’ä¸€åŒ–ç»Ÿè®¡ï¼ˆç”¨äºè‡ªåŠ¨å½’ä¸€åŒ–ä¸åŒå°ºåº¦çš„å¥–åŠ±ï¼‰
        self.reward_stats = {
            'sparse': {'mean': 0.0, 'std': 1.0, 'count': 0},
            'flat': {'mean': 0.0, 'std': 1.0, 'count': 0},
            'knee': {'mean': 0.0, 'std': 1.0, 'count': 0},
            'rs': {'mean': 0.0, 'std': 1.0, 'count': 0},
            'rsh': {'mean': 0.0, 'std': 1.0, 'count': 0},
            'boundary': {'mean': 0.0, 'std': 1.0, 'count': 0}  # ğŸ”¥ è¾¹ç•Œæƒ©ç½šç»Ÿè®¡
        }

    def _init_p0(self, use_aggressive_init: bool = False) -> np.ndarray:
        """
        åœ¨è¾¹ç•Œå†…éšæœºåˆå§‹åŒ–å†…éƒ¨è¡¨ç¤º p0ï¼›I_ph åœ¨ I_sc é™„è¿‘é‡‡æ ·ï¼Œé¿å…æ•´æ¡æ›²çº¿è¢«å‹åˆ°ä½ä½ã€‚
        ğŸ”¥ çªç ´å±€éƒ¨æœ€ä¼˜ç­–ç•¥4ï¼šæ”¯æŒæ¿€è¿›åˆå§‹åŒ–æ¨¡å¼
        ğŸ”¥ å›ºå®šn1å’Œn2ï¼šå¦‚æœå›ºå®šï¼Œåªåˆå§‹åŒ–5ä¸ªå‚æ•°
        """
        b = self.param_bounds
        I_sc = self._curve_feat[1]
        
        if self.fix_n1 and self.fix_n2:
            # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šåªåˆå§‹åŒ–5ä¸ªå‚æ•° [I_ph, log10(I01), log10(I02), Rs, Rsh]
            p = np.zeros(5, dtype=np.float64)
        else:
            # åŒäºŒæç®¡æ¨¡å‹ï¼š7ä¸ªå‚æ•° [I_ph, log10(I01), log10(I02), n1, n2, Rs, Rsh]
            p = np.zeros(7, dtype=np.float64)
        
        # I_phåˆå§‹åŒ–
        if use_aggressive_init:
            p[0] = np.random.uniform(b[0, 0], b[0, 1])  # I_phå®Œå…¨éšæœº
        else:
            lo, hi = max(b[0, 0], I_sc * 0.92), min(b[0, 1], I_sc * 1.08)
            p[0] = np.random.uniform(lo, hi) if hi > lo else float(I_sc)
        
        # I01å’ŒI02åˆå§‹åŒ–
        log_lo1 = np.log10(b[I01_IDX, 0])
        log_hi1 = np.log10(b[I01_IDX, 1])
        log_lo2 = np.log10(b[I02_IDX, 0])
        log_hi2 = np.log10(b[I02_IDX, 1])
        
        if use_aggressive_init:
            p[I01_IDX] = np.random.uniform(log_lo1, log_hi1)
            p[I02_IDX] = np.random.uniform(log_lo2, log_hi2)
        else:
            p[I01_IDX] = np.random.uniform(log_lo1 + (log_hi1 - log_lo1) * 0.2, log_lo1 + (log_hi1 - log_lo1) * 0.8)
            p[I02_IDX] = np.random.uniform(log_lo2 + (log_hi2 - log_lo2) * 0.2, log_lo2 + (log_hi2 - log_lo2) * 0.8)
        
        # Rså’ŒRshåˆå§‹åŒ–
        if self.fix_n1 and self.fix_n2:
            # å›ºå®šæ¨¡å¼ï¼šåªæœ‰5ä¸ªå‚æ•°ï¼Œç´¢å¼•3å’Œ4æ˜¯Rså’ŒRsh
            if use_aggressive_init:
                p[3] = np.random.uniform(b[5, 0], b[5, 1])  # Rs
                p[4] = np.random.uniform(b[6, 0], b[6, 1])  # Rsh
            else:
                p[3] = np.random.uniform(b[5, 0] + (b[5, 1] - b[5, 0]) * 0.1, b[5, 0] + (b[5, 1] - b[5, 0]) * 0.5)  # Rs
                p[4] = np.random.uniform(b[6, 0] + (b[6, 1] - b[6, 0]) * 0.2, b[6, 0] + (b[6, 1] - b[6, 0]) * 0.8)  # Rsh
        else:
            # å®Œæ•´æ¨¡å¼ï¼š7ä¸ªå‚æ•°
            if use_aggressive_init:
                p[3] = np.random.uniform(b[3, 0], b[3, 1])  # n1
                p[4] = np.random.uniform(b[4, 0], b[4, 1])  # n2
                p[5] = np.random.uniform(b[5, 0], b[5, 1])  # Rs
                p[6] = np.random.uniform(b[6, 0], b[6, 1])  # Rsh
            else:
                p[3] = np.random.uniform(b[3, 0] + (b[3, 1] - b[3, 0]) * 0.2, b[3, 0] + (b[3, 1] - b[3, 0]) * 0.8)  # n1
                p[4] = np.random.uniform(b[4, 0] + (b[4, 1] - b[4, 0]) * 0.2, b[4, 0] + (b[4, 1] - b[4, 0]) * 0.8)  # n2
                p[5] = np.random.uniform(b[5, 0] + (b[5, 1] - b[5, 0]) * 0.1, b[5, 0] + (b[5, 1] - b[5, 0]) * 0.5)  # Rs
                p[6] = np.random.uniform(b[6, 0] + (b[6, 1] - b[6, 0]) * 0.2, b[6, 0] + (b[6, 1] - b[6, 0]) * 0.8)  # Rsh
        
        return p
    
    def _normalize_trainable_params(self, p_internal: np.ndarray) -> np.ndarray:
        """å½’ä¸€åŒ–å¯è®­ç»ƒå‚æ•°ï¼ˆå›ºå®šn1å’Œn2æ¨¡å¼ï¼Œåªå½’ä¸€åŒ–5ä¸ªå‚æ•°ï¼‰"""
        b = self.param_bounds
        n = np.zeros(5, dtype=np.float32)
        # I_ph
        n[0] = (p_internal[0] - b[0, 0]) / (b[0, 1] - b[0, 0] + 1e-12)
        # log10(I01)
        log_lo1 = np.log10(b[I01_IDX, 0])
        log_hi1 = np.log10(b[I01_IDX, 1])
        n[I01_IDX] = (p_internal[I01_IDX] - log_lo1) / (log_hi1 - log_lo1 + 1e-12)
        # log10(I02)
        log_lo2 = np.log10(b[I02_IDX, 0])
        log_hi2 = np.log10(b[I02_IDX, 1])
        n[I02_IDX] = (p_internal[I02_IDX] - log_lo2) / (log_hi2 - log_lo2 + 1e-12)
        # Rs (ç´¢å¼•3åœ¨5å‚æ•°æ¨¡å¼ä¸­å¯¹åº”åŸç´¢å¼•5)
        n[3] = (p_internal[3] - b[5, 0]) / (b[5, 1] - b[5, 0] + 1e-12)
        # Rsh (ç´¢å¼•4åœ¨5å‚æ•°æ¨¡å¼ä¸­å¯¹åº”åŸç´¢å¼•6)
        n[4] = (p_internal[4] - b[6, 0]) / (b[6, 1] - b[6, 0] + 1e-12)
        return np.clip(n, 0.0, 1.0)
    
    def _expand_to_full_params(self, p_trainable: np.ndarray) -> np.ndarray:
        """å°†5ä¸ªå¯è®­ç»ƒå‚æ•°æ‰©å±•ä¸º7ä¸ªå®Œæ•´å‚æ•°ï¼ˆæ·»åŠ å›ºå®šçš„n1å’Œn2ï¼‰"""
        if self.fix_n1 and self.fix_n2:
            p_full = np.zeros(7, dtype=np.float64)
            p_full[0] = p_trainable[0]  # I_ph
            p_full[I01_IDX] = p_trainable[I01_IDX]  # log10(I01)
            p_full[I02_IDX] = p_trainable[I02_IDX]  # log10(I02)
            p_full[3] = self.fixed_n1  # n1å›ºå®š
            p_full[4] = self.fixed_n2  # n2å›ºå®š
            p_full[5] = p_trainable[3]  # Rs
            p_full[6] = p_trainable[4]  # Rsh
            return p_full
        else:
            return p_trainable
    
    def _build_state(
        self,
        t: int,
        p_internal: np.ndarray,
        f_t: float,
        delta_f_t: float,
        f0: float,
    ) -> np.ndarray:
        """
        æ”¹è¿›ï¼šæ„å»ºçŠ¶æ€å‘é‡ï¼Œä½¿ç”¨æ›´é²æ£’çš„å½’ä¸€åŒ–æ–¹æ³•ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚
        çŠ¶æ€å‘é‡ï¼šæ›²çº¿ç‰¹å¾(9) + å‚æ•°å½’ä¸€(5æˆ–7) + log(1+f) + delta_f å½’ä¸€ + t/Tã€‚
        ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šå‚æ•°å½’ä¸€ä»7å˜æˆ5ã€‚
        """
        # ğŸ”¥ å¦‚æœå›ºå®šn1å’Œn2ï¼Œåªå½’ä¸€åŒ–5ä¸ªå‚æ•°
        if self.fix_n1 and self.fix_n2:
            params_norm = self._normalize_trainable_params(p_internal)
        else:
            params_norm = internal_to_normalized(p_internal, self.param_bounds)
        # æ”¹è¿›ï¼šfå€¼çš„å½’ä¸€åŒ–ï¼Œä½¿ç”¨æ›´é²æ£’çš„æ–¹æ³•
        # ä½¿ç”¨å¹³æ»‘çš„å¯¹æ•°å˜æ¢ï¼Œé¿å…få€¼å°ºåº¦å·®å¼‚è¿‡å¤§
        log_f = np.log10(1.0 + f_t)
        # æ”¾å®½log_fçš„èŒƒå›´ï¼Œé¿å…è£å‰ªæœ‰æ•ˆæ•°æ®
        log_f = np.clip(log_f, -5.0, 3.0)  # ä»[-3.0, 2.0]æ”¾å®½åˆ°[-5.0, 3.0]
        
        # æ”¹è¿›ï¼šdelta_fçš„å½’ä¸€åŒ–ï¼Œä½¿ç”¨æ›´é²æ£’çš„æ–¹æ³•
        denom = max(f0, 1e-10)
        # æ”¾å®½delta_f_normçš„èŒƒå›´ï¼Œé¿å…è£å‰ªæœ‰æ•ˆæ•°æ®
        delta_f_norm = np.clip(delta_f_t / denom, -5.0, 5.0)  # ä»[-2.0, 2.0]æ”¾å®½åˆ°[-5.0, 5.0]
        
        progress = float(t) / max(self.T_max, 1)
        s = np.concatenate([
            self._curve_feat_norm,
            params_norm,
            [log_f, delta_f_norm, progress],
        ]).astype(np.float32)
        return s

    def _action_to_delta(self, a: np.ndarray) -> np.ndarray:
        """     
        å°† Actor è¾“å‡ºçš„åŸå§‹åŠ¨ä½œ a æ˜ å°„ä¸ºå‚æ•°å¢é‡ Î”pã€‚
        ä½¿ç”¨ tanh å‹ç¼©åˆ° [-1,1] å†æŒ‰ max_delta ç¼©æ”¾ï¼Œé¿å…å¹…åº¦è¿‡å¤§ã€‚
        ç­–ç•¥æ¢¯åº¦ä»åŸºäºåŸå§‹ a çš„ log Ï€(a|s)ã€‚
        """
        x = np.tanh(np.asarray(a, dtype=np.float64))
        return x * self.max_delta
    
    def _compute_boundary_penalty(self, params: np.ndarray, bounds: np.ndarray) -> float:
        """è®¡ç®—è¾¹ç•Œæƒ©ç½šï¼šå‚æ•°æ¥è¿‘è¾¹ç•Œæ—¶ç»™äºˆé€‚åº¦æƒ©ç½šï¼ˆå·²ç¦ç”¨ï¼‰"""
        # ğŸ”¥ å·²ç¦ç”¨è¾¹ç•Œæƒ©ç½šï¼šå…è®¸æ¢ç´¢è¾¹ç•Œé™„è¿‘çš„è§£ï¼Œè®©clip_params_to_boundså¤„ç†è¾¹ç•Œå³å¯
        return 0.0
        
        # ä»¥ä¸‹ä»£ç å·²ç¦ç”¨ï¼Œä¿ç•™ä¾›å‚è€ƒ
        if not ParamAccessor.is_double_diode(params):
            return 0.0  # å•äºŒæç®¡æ¨¡å‹æš‚ä¸å¤„ç†è¾¹ç•Œæƒ©ç½š
        
        penalty = 0.0
        margin = TrainingConfig.BOUNDARY_MARGIN
        tolerance = TrainingConfig.BOUNDARY_TOLERANCE
        scale = TrainingConfig.REWARD_SCALE * TrainingConfig.BOUNDARY_PENALTY_SCALE
        
        # I02å’Œn2æ˜¯é‡ç‚¹å…³æ³¨çš„å‚æ•°ï¼ˆç»å¸¸å¡åœ¨è¾¹ç•Œï¼‰
        param_configs = [
            ('I02', 2, True, 0.3),   # (å‚æ•°å, ç´¢å¼•, æ˜¯å¦log10ç©ºé—´, æƒ©ç½šç³»æ•°)
            ('n2', 4, False, 0.4),
            ('I01', 1, True, 0.3),
            ('I_ph', 0, False, 0.2),
            ('n1', 3, False, 0.2),
            ('Rs', 5, False, 0.2),
            ('Rsh', 6, False, 0.2),
        ]
        
        for param_name, idx, is_log, penalty_coef in param_configs:
            if is_log:
                # log10ç©ºé—´å‚æ•°
                log_val = np.log10(max(params[idx], 1e-60))
                log_range = np.log10(bounds[idx, 1]) - np.log10(bounds[idx, 0])
                dist_low = (log_val - np.log10(bounds[idx, 0])) / (log_range + 1e-12)
                dist_high = (np.log10(bounds[idx, 1]) - log_val) / (log_range + 1e-12)
            else:
                # çº¿æ€§ç©ºé—´å‚æ•°
                param_range = bounds[idx, 1] - bounds[idx, 0]
                dist_low = (params[idx] - bounds[idx, 0]) / (param_range + 1e-12)
                dist_high = (bounds[idx, 1] - params[idx]) / (param_range + 1e-12)
            
            dist_min = min(dist_low, dist_high)
            if dist_min < tolerance:
                penalty -= scale * penalty_coef
            elif dist_min < margin:
                penalty -= (margin - dist_min) / margin * scale * penalty_coef
        
        return penalty
    
    def _compute_rewards(
        self, 
        params_next: np.ndarray, 
        f_prev: float, 
        f_next: float,
        bounds: np.ndarray
    ) -> Dict[str, float]:
        """è®¡ç®—æ‰€æœ‰å¥–åŠ±åˆ†é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        I_sc = self._curve_feat[1]
        is_double = ParamAccessor.is_double_diode(params_next)
        
        # 1. ç¨€ç–å¥–åŠ±ï¼ˆä¸»è¦ä¿¡å·ï¼‰
        r_sparse = float(f_prev - f_next) * TrainingConfig.REWARD_SCALE
        
        # 2. å½¢çŠ¶å¥–åŠ±
        I_ph = ParamAccessor.get_param(params_next, 'I_ph')
        I_ph_error = abs(I_ph - I_sc) / (I_sc + 1e-6)
        r_flat = -I_ph_error * TrainingConfig.REWARD_SCALE
        
        # 3. é™¡é™æ®µå¥–åŠ±
        I0_total = ParamAccessor.get_I0_total(params_next)
        log_I0 = np.log10(max(I0_total, 1e-60))
        r_knee = (log_I0 + 40.0) / 10.0 * TrainingConfig.REWARD_SCALE
        
        # 4. Rså¥–åŠ±
        Rs = ParamAccessor.get_param(params_next, 'Rs')
        Rs_idx = 5 if is_double else 3
        Rs_range = bounds[Rs_idx, 1] - bounds[Rs_idx, 0]
        Rs_center = (bounds[Rs_idx, 0] + bounds[Rs_idx, 1]) / 2.0
        Rs_error = abs(Rs - Rs_center) / (Rs_range + 1e-6)
        r_rs = -Rs_error * TrainingConfig.REWARD_SCALE
        
        # 5. Rshå¥–åŠ±
        Rsh = ParamAccessor.get_param(params_next, 'Rsh')
        Rsh_idx = 6 if is_double else 4
        Rsh_min = bounds[Rsh_idx, 0] * 1.5
        r_rsh = -((Rsh_min - Rsh) / (Rsh_min + 1e-6)) * TrainingConfig.REWARD_SCALE if Rsh < Rsh_min else 0.0
        
        # 6. è¾¹ç•Œæƒ©ç½š
        r_boundary = self._compute_boundary_penalty(params_next, bounds)
        
        return {
            'sparse': r_sparse,
            'flat': r_flat,
            'knee': r_knee,
            'rs': r_rs,
            'rsh': r_rsh,
            'boundary': r_boundary
        }

    def _get_reward_weights(self, epoch: int, total_epochs: int) -> Tuple[float, float, float]:
        """
        æ”¹è¿›ï¼šæ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´å¥–åŠ±æƒé‡ï¼Œå¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ã€‚
        è®­ç»ƒåˆæœŸï¼šå…³æ³¨æ•´ä½“æ‹Ÿåˆï¼ˆsparseå¥–åŠ±æƒé‡é«˜ï¼‰
        è®­ç»ƒä¸­æœŸï¼šå¹³è¡¡å„é¡¹ï¼ˆå„é¡¹æƒé‡å‡è¡¡ï¼‰
        è®­ç»ƒåæœŸï¼šå…³æ³¨ç»†èŠ‚ï¼ˆshapeå¥–åŠ±æƒé‡é«˜ï¼‰
        """
        progress = epoch / max(total_epochs, 1)
        if progress < 0.3:
            # è®­ç»ƒåˆæœŸï¼ˆ0-30%ï¼‰ï¼šå…³æ³¨æ•´ä½“æ‹Ÿåˆï¼Œå¿«é€Ÿé™ä½è¯¯å·®
            return (0.5, 0.3, 0.2)  # [sparse, flat, knee]
        elif progress < 0.7:
            # è®­ç»ƒä¸­æœŸï¼ˆ30-70%ï¼‰ï¼šå¹³è¡¡å„é¡¹ï¼Œç¨³å®šä¼˜åŒ–ï¼Œå¼€å§‹å…³æ³¨I0
            return (0.35, 0.35, 0.30)
        else:
            # è®­ç»ƒåæœŸï¼ˆ70-100%ï¼‰ï¼šæ›´å…³æ³¨I0ç»†èŠ‚ï¼Œç²¾ç»†è°ƒæ•´ï¼ˆI0æƒé‡æå‡åˆ°45%ï¼‰
            return (0.25, 0.30, 0.45)  # I0æƒé‡ä»40%æå‡åˆ°45%ï¼Œæ›´å¼ºåˆ¶å­¦ä¹ 
    
    def _normalize_reward(self, reward: float, reward_type: str) -> float:
        """
        è‡ªåŠ¨å½’ä¸€åŒ–å¥–åŠ±ï¼Œè®©ä¸åŒå¥–åŠ±çš„å°ºåº¦ä¸€è‡´ï¼Œå‡å°‘å¯¹æƒé‡çš„ä¾èµ–ã€‚
        ä½¿ç”¨åœ¨çº¿æ›´æ–°çš„å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡ŒZ-scoreå½’ä¸€åŒ–ã€‚
        """
        stats = self.reward_stats[reward_type]
        count = stats['count']
        
        if count == 0:
            # ç¬¬ä¸€æ¬¡ï¼šç›´æ¥ä½¿ç”¨åŸå§‹å€¼
            stats['mean'] = reward
            stats['std'] = abs(reward) + 1e-6
            stats['count'] = 1
            return reward / (abs(reward) + 1e-6)  # å½’ä¸€åŒ–åˆ°[-1, 1]é™„è¿‘
        else:
            # åœ¨çº¿æ›´æ–°å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
            alpha = 0.01  # æ›´æ–°ç‡
            old_mean = stats['mean']
            old_std = stats['std']
            
            # æ›´æ–°å‡å€¼
            new_mean = (1 - alpha) * old_mean + alpha * reward
            # æ›´æ–°æ ‡å‡†å·®ï¼ˆä½¿ç”¨ç§»åŠ¨å¹³å‡ï¼‰
            new_std = np.sqrt((1 - alpha) * (old_std ** 2) + alpha * (reward - old_mean) ** 2)
            new_std = max(new_std, 1e-6)  # é¿å…é™¤é›¶
            
            stats['mean'] = new_mean
            stats['std'] = new_std
            stats['count'] += 1
            
            # Z-scoreå½’ä¸€åŒ–
            normalized = (reward - new_mean) / new_std
            # è£å‰ªåˆ°åˆç†èŒƒå›´ï¼Œé¿å…æç«¯å€¼
            return np.clip(normalized, -10.0, 10.0)
    
    def _update_adaptive_weights(self, epoch: int, total_epochs: int):
        """
        æ ¹æ®å¥–åŠ±å†å²è¡¨ç°è‡ªåŠ¨è°ƒæ•´æƒé‡ã€‚
        å¦‚æœæŸä¸ªå¥–åŠ±ä¸€ç›´å¾ˆå°ï¼ˆè¯´æ˜ç½‘ç»œæ²¡æœ‰å­¦ä¹ åˆ°ï¼‰ï¼Œå°±å¢åŠ å®ƒçš„æƒé‡ã€‚
        å¦‚æœæŸä¸ªå¥–åŠ±ä¸€ç›´å¾ˆå¤§ï¼ˆè¯´æ˜ç½‘ç»œå·²ç»å­¦å¾—å¾ˆå¥½ï¼‰ï¼Œå°±å‡å°‘å®ƒçš„æƒé‡ã€‚
        """
        if len(self.reward_history['sparse']) < 100:
            return  # å†å²æ•°æ®ä¸è¶³ï¼Œä¸è°ƒæ•´
        
        # è®¡ç®—æœ€è¿‘100ä¸ªepisodeçš„å¹³å‡å¥–åŠ±
        window = 100
        recent_sparse = np.mean(self.reward_history['sparse'][-window:])
        recent_flat = np.mean(self.reward_history['flat'][-window:])
        recent_knee = np.mean(self.reward_history['knee'][-window:])
        recent_rs = np.mean(self.reward_history['rs'][-window:])
        recent_rsh = np.mean(self.reward_history['rsh'][-window:])
        recent_boundary = np.mean(self.reward_history['boundary'][-window:]) if len(self.reward_history['boundary']) > 0 else 0.0
        
        # å½’ä¸€åŒ–åˆ°[0, 1]èŒƒå›´ï¼ˆç›¸å¯¹å¤§å°ï¼‰
        rewards = np.array([recent_sparse, recent_flat, recent_knee, recent_rs, recent_rsh, recent_boundary])
        rewards_min = np.min(rewards)
        rewards_max = np.max(rewards)
        if rewards_max - rewards_min > 1e-6:
            rewards_norm = (rewards - rewards_min) / (rewards_max - rewards_min)
        else:
            rewards_norm = np.array([0.15, 0.15, 0.15, 0.05, 0.05, 0.15])  # å¦‚æœéƒ½å·®ä¸å¤šï¼Œç»™boundaryè¾ƒé«˜æƒé‡
        
        # å¥–åŠ±å°çš„æƒé‡å¢åŠ ï¼Œå¥–åŠ±å¤§çš„æƒé‡å‡å°‘ï¼ˆä½†ä¿æŒæ€»å’Œä¸º1ï¼‰
        # ä½¿ç”¨softmaxçš„é€†æ“ä½œï¼šå¥–åŠ±å°çš„ç»™æ›´å¤§æƒé‡
        inverse_rewards = 1.0 - rewards_norm + 0.1  # +0.1é¿å…æƒé‡ä¸º0
        weights = inverse_rewards / np.sum(inverse_rewards)
        
        # å¹³æ»‘æ›´æ–°ï¼ˆé¿å…æƒé‡å˜åŒ–å¤ªå¿«ï¼‰
        alpha = 0.05  # æ›´æ–°ç‡
        self.adaptive_weights['sparse'] = (1 - alpha) * self.adaptive_weights['sparse'] + alpha * weights[0]
        self.adaptive_weights['flat'] = (1 - alpha) * self.adaptive_weights['flat'] + alpha * weights[1]
        self.adaptive_weights['knee'] = (1 - alpha) * self.adaptive_weights['knee'] + alpha * weights[2]
        self.adaptive_weights['rs'] = (1 - alpha) * self.adaptive_weights['rs'] + alpha * weights[3]
        self.adaptive_weights['rsh'] = (1 - alpha) * self.adaptive_weights['rsh'] + alpha * weights[4]
        # è¾¹ç•Œæƒ©ç½šæƒé‡æ›´æ–°ï¼ˆå·²ç¦ç”¨ï¼Œå› ä¸ºè¾¹ç•Œæƒ©ç½šå·²è®¾ä¸º0ï¼‰
        # if 'boundary' in self.adaptive_weights:
        #     self.adaptive_weights['boundary'] = (1 - alpha) * self.adaptive_weights['boundary'] + alpha * weights[5]
        
        # å½’ä¸€åŒ–ç¡®ä¿æ€»å’Œä¸º1
        total = sum(self.adaptive_weights.values())
        for key in self.adaptive_weights:
            self.adaptive_weights[key] /= total
        
        # ç†æ€§è°ƒæ•´ï¼šè¾¹ç•Œæƒ©ç½šæƒé‡ä¿æŒé€‚åº¦ï¼ˆä¸è¦è¿‡å¤§ï¼‰
        # è¾¹ç•Œæƒ©ç½šæƒé‡é™åˆ¶ï¼ˆå·²ç¦ç”¨ï¼Œå› ä¸ºè¾¹ç•Œæƒ©ç½šå·²è®¾ä¸º0ï¼‰
        # if 'boundary' in self.adaptive_weights:
        #     self.adaptive_weights['boundary'] = min(self.adaptive_weights['boundary'], 0.15)  # æœ€å¤š15%æƒé‡
            # é‡æ–°å½’ä¸€åŒ–
            total = sum(self.adaptive_weights.values())
            for key in self.adaptive_weights:
                self.adaptive_weights[key] /= total
    
    def _run_episode(
        self,
        explore: bool = True,
        current_epoch: int = 0,  # æ–°å¢ï¼šå½“å‰è®­ç»ƒè½®æ•°
        total_epochs: int = 500,  # æ–°å¢ï¼šæ€»è®­ç»ƒè½®æ•°
    ) -> Tuple[List[Dict[str, Any]], float, np.ndarray]:
        """
        è·‘ä¸€ä¸ª episodeï¼šå¤šæ­¥è¿­ä»£ï¼Œæ”¶é›† (s_t, a_t, r_t, log_prob_t, V_t)ã€‚
        å¥–åŠ± r_t = f(p_t) - f(p_{t+1})ï¼›ç¬¬ä¸€æ­¥ç”¨ f(p_0)-f(p_1)ã€‚
        è¿”å›ï¼š(trajectory, æœ€ç»ˆ f, æœ€ç»ˆå‚æ•°ç‰©ç†å€¼)
        """
        b = self.param_bounds
        trajectory: List[Dict[str, Any]] = []
        # æ¿€è¿›åˆå§‹åŒ–ï¼ˆé€‚åº¦ä½¿ç”¨ï¼‰
        use_aggressive = (current_epoch > TrainingConfig.EXPLORATION_BOOST_THRESHOLD and 
                         current_epoch % 20 == 0)
        p = self._init_p0(use_aggressive_init=use_aggressive)
        # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šæ‰©å±•ä¸ºå®Œæ•´å‚æ•°ç”¨äºè®¡ç®—ç›®æ ‡å‡½æ•°
        if self.fix_n1 and self.fix_n2:
            p_full = self._expand_to_full_params(p)
            params_phys = internal_to_params(p_full, b)
        else:
            params_phys = internal_to_params(p, b)
        f_prev = objective_function(params_phys, self.V, self.I_meas, self.I_min, self.I_max)
        f0 = max(f_prev, 1e-10)
        delta_f_prev = 0.0

        # è®¡ç®—æ¢ç´¢å› å­ï¼ˆä½¿ç”¨é…ç½®ç±»ï¼‰
        base_exploration = TrainingConfig.EXPLORATION_INITIAL - \
                          (TrainingConfig.EXPLORATION_INITIAL - TrainingConfig.EXPLORATION_FINAL) * \
                          (current_epoch / max(total_epochs, 1))
        base_exploration = max(base_exploration, TrainingConfig.EXPLORATION_FINAL)
        
        # ğŸ”¥ æ£€æµ‹å‚æ•°æ˜¯å¦åœ¨è¾¹ç•Œï¼Œå¦‚æœåœ¨è¾¹ç•Œåˆ™å¤§å¹…å¢å¼ºæ¢ç´¢
        is_at_boundary = False
        # æ ¹æ®æ˜¯å¦å›ºå®šn1å’Œn2ï¼Œè°ƒæ•´è¾¹ç•Œæ£€æµ‹é€»è¾‘
        if self.fix_n1 and self.fix_n2:
            # 5å‚æ•°æ¨¡å¼ï¼šåªæ£€æµ‹5ä¸ªå¯è®­ç»ƒå‚æ•°
            param_indices_to_check = [0, I01_IDX, I02_IDX, 3, 4]  # I_ph, I01, I02, Rs, Rsh
            bound_indices = [0, I01_IDX, I02_IDX, 5, 6]  # å¯¹åº”çš„è¾¹ç•Œç´¢å¼•
        else:
            # 7å‚æ•°æ¨¡å¼ï¼šæ£€æµ‹æ‰€æœ‰å‚æ•°
            param_indices_to_check = list(range(len(p)))
            bound_indices = list(range(len(p)))
        
        for idx, param_idx in enumerate(param_indices_to_check):
            bound_idx = bound_indices[idx]
            if param_idx in [I01_IDX, I02_IDX]:
                # log10ç©ºé—´å‚æ•°
                log_val = p[param_idx]
                log_lo = np.log10(b[bound_idx, 0])
                log_hi = np.log10(b[bound_idx, 1])
                if abs(log_val - log_lo) < 1e-5 or abs(log_val - log_hi) < 1e-5:
                    is_at_boundary = True
                    break
            else:
                # çº¿æ€§ç©ºé—´å‚æ•°
                if abs(p[param_idx] - b[bound_idx, 0]) < 1e-5 or abs(p[param_idx] - b[bound_idx, 1]) < 1e-5:
                    is_at_boundary = True
                    break
        
        # è®­ç»ƒåæœŸé€‚åº¦å¢åŠ æ¢ç´¢ï¼Œå¦‚æœåœ¨è¾¹ç•Œåˆ™å¤§å¹…å¢å¼º
        if is_at_boundary and explore:
            exploration_factor = min(base_exploration * 3.0, 2.0)  # è¾¹ç•Œæ—¶æ¢ç´¢å› å­Ã—3ï¼Œæœ€å¤š2.0
        elif current_epoch > TrainingConfig.EXPLORATION_BOOST_THRESHOLD:
            exploration_factor = min(base_exploration * TrainingConfig.EXPLORATION_BOOST_FACTOR, 1.5)
        else:
            exploration_factor = base_exploration
        
        for t in range(self.T_max):
            # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šæ„å»ºçŠ¶æ€æ—¶ä½¿ç”¨æ­£ç¡®çš„å‚æ•°ç»´åº¦
            # æ„å»ºå½“å‰çŠ¶æ€ï¼ˆæ›²çº¿ç‰¹å¾ + å½“å‰å‚æ•° + å½“å‰è¯¯å·® + æ­¥æ•°ï¼‰
            s = self._build_state(t, p, f_prev, delta_f_prev, f0)
            # ç”¨ tensor(list) é¿å… torch.from_numpyï¼Œé˜²æ­¢ NumPy DLL ä¸ PyTorch å†²çªæ—¶æŠ¥é”™
            s_t = torch.tensor(s.tolist(), dtype=torch.float32, device=self.device).unsqueeze(0)
      
            with torch.no_grad():
                V_t = self.critic(s_t).squeeze(0).item()

            # æ”¹è¿›ï¼šæ¢ç´¢æ—¶ä½¿ç”¨è‡ªé€‚åº”æ¢ç´¢å› å­ï¼Œè¯„ä¼°æ—¶ä½¿ç”¨æœ€å°æ¢ç´¢ï¼ˆç¡®å®šæ€§ç­–ç•¥ï¼‰
            # ç”¨ .tolist() ä»£æ›¿ .numpy()ï¼Œé¿å… PyTorch ä¸ NumPy DLL å†²çªæ—¶æŠ¥ "Numpy is not available"
            if explore:
                a_tensor, log_prob_t = self.actor.sample(s_t, exploration_factor)
                a_raw = a_tensor.cpu().squeeze(0).tolist()
            else:
                mean, _ = self.actor(s_t, exploration_factor=0.3)  # è¯„ä¼°æ—¶ä½¿ç”¨æœ€å°æ¢ç´¢
                a_raw = mean.cpu().squeeze(0).tolist()
                log_prob_t = self.actor.log_prob(s_t, mean, exploration_factor=0.3)

            delta = self._action_to_delta(a_raw)
            # é€‚åº¦æ·»åŠ å™ªå£°ï¼ˆä½¿ç”¨é…ç½®ç±»ï¼‰
            if current_epoch > TrainingConfig.NOISE_THRESHOLD_EPOCH and explore:
                noise_scale = TrainingConfig.NOISE_SCALE_BASE * (current_epoch / max(total_epochs, 1))
                extra_noise = np.random.randn(len(delta)) * noise_scale
                delta = delta + extra_noise
            
            # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šåªæ›´æ–°5ä¸ªå‚æ•°
            if self.fix_n1 and self.fix_n2:
                # åªæ›´æ–°5ä¸ªå¯è®­ç»ƒå‚æ•°
                p_next_trainable = clip_params_to_bounds_trainable(p + self.alpha * delta, b)
                # æ‰©å±•ä¸ºå®Œæ•´7å‚æ•°ç”¨äºè®¡ç®—ç›®æ ‡å‡½æ•°
                p_next_full = self._expand_to_full_params(p_next_trainable)
                params_next = internal_to_params(p_next_full, b)
                p_next = p_next_trainable  # ä¿å­˜5å‚æ•°ç‰ˆæœ¬ç”¨äºä¸‹ä¸€è½®
                
                # ğŸ”¥ è¾¹ç•Œåå¼¹æœºåˆ¶ï¼ˆ5å‚æ•°æ¨¡å¼ï¼‰
                if explore:
                    bounce_factor = 0.05
                    param_mapping = [0, I01_IDX, I02_IDX, 5, 6]  # 5å‚æ•°åˆ°7å‚æ•°è¾¹ç•Œçš„æ˜ å°„
                    for i, bound_idx in enumerate(param_mapping):
                        if i in [I01_IDX, I02_IDX]:
                            log_val = p_next[i]
                            log_lo = np.log10(b[bound_idx, 0])
                            log_hi = np.log10(b[bound_idx, 1])
                            if abs(log_val - log_lo) < 1e-6:
                                p_next[i] += bounce_factor * (log_hi - log_lo)
                            elif abs(log_val - log_hi) < 1e-6:
                                p_next[i] -= bounce_factor * (log_hi - log_lo)
                        else:
                            param_range = b[bound_idx, 1] - b[bound_idx, 0]
                            if abs(p_next[i] - b[bound_idx, 0]) < 1e-6:
                                p_next[i] += bounce_factor * param_range
                            elif abs(p_next[i] - b[bound_idx, 1]) < 1e-6:
                                p_next[i] -= bounce_factor * param_range
                    p_next = clip_params_to_bounds_trainable(p_next, b)
                    p_next_full = self._expand_to_full_params(p_next)
                    params_next = internal_to_params(p_next_full, b)
            else:
                p_next = clip_params_to_bounds(p + self.alpha * delta, b)
                params_next = internal_to_params(p_next, b)
                
                # ğŸ”¥ è¾¹ç•Œåå¼¹æœºåˆ¶ï¼ˆ7å‚æ•°æ¨¡å¼ï¼‰
                if explore:
                    bounce_factor = 0.05
                    for i in range(len(p_next)):
                        if i in [I01_IDX, I02_IDX]:
                            log_val = p_next[i]
                            log_lo = np.log10(b[i, 0])
                            log_hi = np.log10(b[i, 1])
                            if abs(log_val - log_lo) < 1e-6:
                                p_next[i] += bounce_factor * (log_hi - log_lo)
                            elif abs(log_val - log_hi) < 1e-6:
                                p_next[i] -= bounce_factor * (log_hi - log_lo)
                        else:
                            param_range = b[i, 1] - b[i, 0]
                            if abs(p_next[i] - b[i, 0]) < 1e-6:
                                p_next[i] += bounce_factor * param_range
                            elif abs(p_next[i] - b[i, 1]) < 1e-6:
                                p_next[i] -= bounce_factor * param_range
                    p_next = clip_params_to_bounds(p_next, b)
                    params_next = internal_to_params(p_next, b)
            
            # å‚æ•°åˆç†æ€§æ£€æŸ¥
            I_sc = self._curve_feat[1]
            I_ph_next = ParamAccessor.get_param(params_next, 'I_ph')
            Rs_next = ParamAccessor.get_param(params_next, 'Rs')
            
            # å‚æ•°åˆç†æ€§æ£€æŸ¥ï¼ˆæƒ©ç½šä¼šåœ¨å¥–åŠ±è®¡ç®—ä¸­å¤„ç†ï¼‰
            
            f_next = objective_function(params_next, self.V, self.I_meas, self.I_min, self.I_max)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„å¥–åŠ±è®¡ç®—å‡½æ•°ï¼ˆç®€åŒ–ä»£ç ï¼Œæ¶ˆé™¤é‡å¤ï¼‰
            rewards_raw = self._compute_rewards(params_next, f_prev, f_next, b)
            r_sparse_raw = rewards_raw['sparse']
            shape_reward_flat_raw = rewards_raw['flat']
            shape_reward_knee_raw = rewards_raw['knee']
            shape_reward_rs_raw = rewards_raw['rs']
            shape_reward_rsh_raw = rewards_raw['rsh']
            boundary_penalty_raw = rewards_raw['boundary']
            
            # ========== è‡ªåŠ¨å½’ä¸€åŒ–å¥–åŠ±ï¼ˆè®©ä¸åŒå¥–åŠ±çš„å°ºåº¦ä¸€è‡´ï¼‰==========
            r_sparse_norm = self._normalize_reward(r_sparse_raw, 'sparse')
            shape_reward_flat_norm = self._normalize_reward(shape_reward_flat_raw, 'flat')
            shape_reward_knee_norm = self._normalize_reward(shape_reward_knee_raw, 'knee')
            shape_reward_rs_norm = self._normalize_reward(shape_reward_rs_raw, 'rs')
            shape_reward_rsh_norm = self._normalize_reward(shape_reward_rsh_raw, 'rsh')
            # è¾¹ç•Œæƒ©ç½šå½’ä¸€åŒ–
            if 'boundary' in self.reward_stats:
                boundary_penalty_norm = self._normalize_reward(boundary_penalty_raw, 'boundary')
            else:
                boundary_penalty_norm = boundary_penalty_raw / TrainingConfig.REWARD_SCALE
            
            # ========== è®°å½•å¥–åŠ±å†å²ï¼ˆç”¨äºè‡ªé€‚åº”æƒé‡è°ƒæ•´ï¼‰==========
            self.reward_history['sparse'].append(r_sparse_raw)
            self.reward_history['flat'].append(shape_reward_flat_raw)
            self.reward_history['knee'].append(shape_reward_knee_raw)
            self.reward_history['rs'].append(shape_reward_rs_raw)
            self.reward_history['rsh'].append(shape_reward_rsh_raw)
            self.reward_history['boundary'].append(boundary_penalty_raw)  # ğŸ”¥ è®°å½•è¾¹ç•Œæƒ©ç½š
            
            # ========== ç»„åˆå¥–åŠ±ï¼šä½¿ç”¨è‡ªé€‚åº”æƒé‡ ==========
            # é€‰é¡¹1ï¼šä½¿ç”¨è‡ªé€‚åº”æƒé‡ï¼ˆè‡ªåŠ¨è°ƒæ•´ï¼‰- æ¨èï¼
            # è®¾ç½®ä¸ºFalseå¯ä»¥ç¦ç”¨è‡ªé€‚åº”æƒé‡ï¼Œä½¿ç”¨å›ºå®šæƒé‡
            use_adaptive = True  # è®¾ç½®ä¸ºFalseå¯ä»¥ç¦ç”¨è‡ªé€‚åº”æƒé‡
            
            if use_adaptive:
                # ä½¿ç”¨è‡ªé€‚åº”æƒé‡ï¼ˆä¼šæ ¹æ®å†å²è¡¨ç°è‡ªåŠ¨è°ƒæ•´ï¼‰
                r_t = (self.adaptive_weights['sparse'] * r_sparse_norm +
                       self.adaptive_weights['flat'] * shape_reward_flat_norm +
                       self.adaptive_weights['knee'] * shape_reward_knee_norm +
                       self.adaptive_weights['rs'] * shape_reward_rs_norm +
                       self.adaptive_weights['rsh'] * shape_reward_rsh_norm +
                       self.adaptive_weights.get('boundary', 0.2) * boundary_penalty_norm)  # ğŸ”¥ æ·»åŠ è¾¹ç•Œæƒ©ç½šï¼ˆä½¿ç”¨geté¿å…KeyErrorï¼‰
            else:
                # ä½¿ç”¨å›ºå®šæƒé‡ï¼ˆåŸæ¥çš„æ–¹æ³•ï¼Œéœ€è¦æ‰‹åŠ¨è°ƒå‚ï¼‰
                w_sparse, w_flat, w_knee = self._get_reward_weights(current_epoch, total_epochs)
                r_t = (w_sparse * r_sparse_norm +
                       w_flat * shape_reward_flat_norm +
                       w_knee * shape_reward_knee_norm +
                       0.04 * shape_reward_rs_norm +
                       0.04 * shape_reward_rsh_norm)
            
            # æ³¨æ„ï¼šå‚æ•°åˆç†æ€§æƒ©ç½šå·²åŒ…å«åœ¨å½¢çŠ¶å¥–åŠ±ä¸­ï¼Œæ— éœ€é¢å¤–æ·»åŠ 

            # å¼‚å¸¸æ—¶ç»™å¤§è´Ÿå¥–åŠ±å¹¶æå‰ç»“æŸ
            if np.isnan(f_next) or np.isinf(f_next) or f_next >= 1e9:
                r_t = -10.0  # å¼‚å¸¸å¥–åŠ±ï¼ˆå½’ä¸€åŒ–åçš„å€¼ï¼‰
                trajectory.append({
                    "s": s, "a": a_raw, "r": r_t,
                    "log_prob": log_prob_t.detach(),
                    "V": V_t,
                })
                break

            trajectory.append({
                "s": s, "a": a_raw, "r": r_t,
                "log_prob": log_prob_t.detach(),
                "V": V_t,
            })
            # ğŸ”¥ æ”¹è¿›ï¼šä½¿ç”¨å½’ä¸€åŒ–åçš„å¥–åŠ±ä½œä¸ºdelta_f_prevï¼Œè€Œä¸æ˜¯åŸå§‹r_t
            # è¿™æ ·å¯ä»¥æ›´å¥½åœ°åæ˜ é•¿æœŸè¶‹åŠ¿ï¼Œå‡å°‘çŸ­è§†
            delta_f_prev = r_t  # r_tå·²ç»æ˜¯å½’ä¸€åŒ–åçš„å¥–åŠ±
            f_prev = f_next
            p = p_next

        # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šè¿”å›å®Œæ•´å‚æ•°
        if self.fix_n1 and self.fix_n2:
            p_full = self._expand_to_full_params(p)
            final_params = internal_to_params(p_full, b)
        else:
            final_params = internal_to_params(p, b)
        return trajectory, f_prev, final_params

    def _compute_returns(self, rewards: List[float]) -> List[float]:
        """
        è®¡ç®—æŠ˜æ‰£å›æŠ¥ R_t = r_t + Î³Â·r_{t+1} + Î³Â²Â·r_{t+2} + ...ï¼Œä»è½¨è¿¹æœ«å°¾å€’æ¨ã€‚
        ğŸ”¥ æ”¹è¿›ï¼šæ·»åŠ æœ€ç»ˆå¥–åŠ±åŠ æˆï¼Œé¼“åŠ±é•¿æœŸä¼˜åŒ–è·¯å¾„
        """
        R = [0.0] * len(rewards)
        run = 0.0
        
        # ğŸ”¥ æœ€ç»ˆå¥–åŠ±åŠ æˆï¼šå¦‚æœè½¨è¿¹æœ€ç»ˆè¯¯å·®ä¸‹é™ï¼Œç»™äºˆé¢å¤–å¥–åŠ±
        # è¿™é¼“åŠ±"å…ˆå˜å·®å†å˜å¥½"çš„è·¯å¾„
        if len(rewards) > 0:
            # è®¡ç®—è½¨è¿¹çš„æœ€ç»ˆè¶‹åŠ¿ï¼ˆæœ€å5æ­¥çš„å¹³å‡å¥–åŠ±ï¼‰
            final_trend = np.mean(rewards[-min(5, len(rewards)):]) if len(rewards) >= 5 else rewards[-1]
            # å¦‚æœæœ€ç»ˆè¶‹åŠ¿ä¸ºæ­£ï¼ˆè¯¯å·®ä¸‹é™ï¼‰ï¼Œç»™äºˆåŠ æˆ
            final_bonus = max(0.0, final_trend * 0.1)  # 10%çš„æœ€ç»ˆè¶‹åŠ¿åŠ æˆ
        else:
            final_bonus = 0.0
        
        for t in reversed(range(len(rewards))):
            run = rewards[t] + self.gamma * run
            # ğŸ”¥ åœ¨æœ€åå‡ æ­¥æ·»åŠ æœ€ç»ˆå¥–åŠ±åŠ æˆï¼Œé¼“åŠ±é•¿æœŸä¼˜åŒ–
            if t >= len(rewards) - 3:  # æœ€å3æ­¥
                R[t] = run + final_bonus
            else:
                R[t] = run
        return R

    def update(self, trajectories: List[List[Dict[str, Any]]]) -> Tuple[float, float]:
        """
        ç”¨å¤šæ¡è½¨è¿¹çš„ (s,a,r,R,V) æ‰¹é‡æ›´æ–° Actor å’Œ Criticã€‚
        Actor: æ¢¯åº¦ä¸Šå‡ E[log pi(a|s) * A]ï¼ŒA = R - V(s)ã€‚
        Critic: MSE(V(s), R)ã€‚
        """
        all_s, all_a, all_R = [], [], []
        for traj in trajectories:
            rewards = [x["r"] for x in traj]
            R_list = self._compute_returns(rewards)
            for i, x in enumerate(traj):
                all_s.append(x["s"])
                all_a.append(x["a"])
                all_R.append(R_list[i])

        # ç”¨ tensor(list) é¿å… torch.from_numpyï¼Œé˜²æ­¢ NumPy DLL ä¸ PyTorch å†²çªæ—¶æŠ¥é”™
        # all_a ä¸­å¯èƒ½æ˜¯ listï¼ˆæ¥è‡ª .tolist()ï¼‰æˆ– arrayï¼Œç»Ÿä¸€è½¬ä¸º list
        S = torch.tensor([(x.tolist() if hasattr(x, "tolist") else x) for x in all_s], dtype=torch.float32, device=self.device)
        A = torch.tensor([(x.tolist() if hasattr(x, "tolist") else x) for x in all_a], dtype=torch.float32, device=self.device)
        R = torch.tensor(all_R, dtype=torch.float32, device=self.device)

        # Criticï¼šæœ€å°åŒ– MSE(V(s), R)ï¼Œè®© V é€¼è¿‘æŠ˜æ‰£å›æŠ¥
        V_pred = self.critic(S)
        loss_c = F.mse_loss(V_pred, R)
        self.opt_critic.zero_grad()
        loss_c.backward()
        torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 1.0) 
        self.opt_critic.step()

        # Advantage A = R - V(s)ï¼Œç”¨å½“å‰ Critic ä¼°è®¡ï¼ˆæ›´æ–°åï¼‰å‡å°‘æ–¹å·®
        with torch.no_grad():
            V_new = self.critic(S)
        adv = R - V_new.detach()

        # Actorï¼šæœ€å¤§åŒ– E[log Ï€(a|s) Â· A]ï¼Œå³ loss = -mean(log Ï€ Â· A)
        # æ”¹è¿›ï¼šæ·»åŠ ç†µæ­£åˆ™åŒ–ï¼Œé¼“åŠ±æ¢ç´¢ï¼Œé¿å…è¿‡æ—©æ”¶æ•›åˆ°æ¬¡ä¼˜è§£
        # æ³¨æ„ï¼šupdateå‡½æ•°ä¸­æ— æ³•ç›´æ¥è·å–epochä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤exploration_factor=1.0
        # å®é™…çš„æ¢ç´¢è°ƒæ•´åœ¨_run_episodeä¸­å®Œæˆ
        log_prob = self.actor.log_prob(S, A, exploration_factor=1.0)
        mean, std = self.actor.forward(S, exploration_factor=1.0)
        dist = torch.distributions.Normal(mean, std + 1e-6)
        entropy = dist.entropy().sum(dim=-1).mean()  # ç­–ç•¥ç†µ
        loss_a = -(log_prob * adv).mean() - TrainingConfig.ENTROPY_COEF * entropy
        self.opt_actor.zero_grad()
        loss_a.backward()
        torch.nn.utils.clip_grad_norm_(self.actor.parameters(), 1.0)
        self.opt_actor.step()

        return float(loss_c.item()), float(loss_a.item())

    def fit(
        self,
        n_epochs: int = 500,  # å¢åŠ è®­ç»ƒè½®æ•°ï¼š300 -> 500ï¼Œç»™ç½‘ç»œæ›´å¤šå­¦ä¹ æ—¶é—´
        episodes_per_epoch: int = 128,  # ä¿æŒ128ï¼Œç¡®ä¿è¶³å¤Ÿçš„æ‰¹é‡å¤§å°ï¼Œä¸å½±å“è®­ç»ƒç¨³å®šæ€§
        eval_interval: int = 10,
        early_stop_patience: int = 10000,  # æ—©åœï¼šå¤§å¹…æé«˜ï¼ˆå‡ ä¹ç¦ç”¨ï¼‰ï¼Œç»™ä¼˜åŒ–å™¨å……åˆ†æ¢ç´¢æ—¶é—´
        early_stop_min_delta: float = 1e-7,  # æ—©åœï¼šä»1e-6é™ä½åˆ°1e-7ï¼Œå…è®¸æ›´å°çš„æ”¹å–„
    ) -> Tuple[np.ndarray, float, List[float]]:
        """
        è®­ç»ƒä¸»å¾ªç¯ã€‚æ¯è½®è·‘å¤šæ¡ episodeï¼Œæ›´æ–° ACï¼›
        å®šæœŸç”¨æ— æ¢ç´¢è·‘ä¸€æ¡è½¨è¿¹ï¼Œè®°å½•æœ€ç»ˆ fã€‚
        è¿”å›ï¼š(best_params, best_f, f_history)
        """
        best_f = float("inf")
        best_params: Optional[np.ndarray] = None
        f_history: List[float] = []
        no_improve_count = 0  # è®°å½•è¿ç»­æœªæ”¹å–„çš„è½®æ•°
        restart_count = 0  # ğŸ”¥ é‡å¯è®¡æ•°å™¨
        
        # ğŸ”¥ çªç ´å±€éƒ¨æœ€ä¼˜ç­–ç•¥2ï¼šè®°å½•æœ€ä½³å‚æ•°ï¼Œç”¨äºé‡å¯
        best_params_internal: Optional[np.ndarray] = None

        for epoch in range(n_epochs):
            trajs = []
            for _ in range(episodes_per_epoch):
                tr, f_end, _ = self._run_episode(explore=True, current_epoch=epoch, total_epochs=n_epochs)
                trajs.append(tr)
            if trajs:
                _ = self.update(trajs)
                # æ›´æ–°å­¦ä¹ ç‡ï¼ˆæ¯100è½®è¡°å‡10%ï¼‰
                self.scheduler_actor.step()
                self.scheduler_critic.step()

            # ğŸ”¥ ä¿®æ”¹æ‰“å°é€»è¾‘ï¼šå‰50æ¬¡æ¯æ¬¡éƒ½æ‰“å°ï¼Œåé¢æ¯10æ¬¡æ‰“å°ä¸€æ¬¡
            should_eval = False
            if epoch < 50:
                # å‰50æ¬¡æ¯æ¬¡éƒ½è¯„ä¼°å’Œæ‰“å°
                should_eval = True
            else:
                # åé¢æ¯10æ¬¡è¯„ä¼°å’Œæ‰“å°ä¸€æ¬¡
                should_eval = (epoch + 1) % eval_interval == 0
            
            if should_eval:
                _, f_eval, p_eval = self._run_episode(explore=False, current_epoch=epoch, total_epochs=n_epochs)  # æ— æ¢ç´¢ï¼Œå–ç¡®å®šæ€§ç­–ç•¥
                f_history.append(f_eval)
                improved = False
                if f_eval < best_f - early_stop_min_delta:  # æœ‰æ˜¾è‘—æ”¹å–„
                    best_f = f_eval
                    best_params = p_eval.copy()
                    # ğŸ”¥ ä¿å­˜å†…éƒ¨è¡¨ç¤ºç”¨äºé‡å¯
                    _, _, best_params_internal_temp = self._run_episode(explore=False, current_epoch=epoch, total_epochs=n_epochs)
                    best_params_internal = best_params_internal_temp.copy() if best_params_internal_temp is not None else None
                    no_improve_count = 0  # é‡ç½®è®¡æ•°å™¨
                    improved = True
                else:
                    # è®¡ç®—æœªæ”¹å–„è®¡æ•°ï¼šå‰50æ¬¡æ¯æ¬¡+1ï¼Œåé¢æ¯æ¬¡+eval_interval
                    increment = 1 if epoch < 50 else eval_interval  
                    no_improve_count += increment  # å¢åŠ æœªæ”¹å–„è®¡æ•°
                
                # ========== è‡ªé€‚åº”æƒé‡æ›´æ–°ï¼ˆæ¯10è½®æ›´æ–°ä¸€æ¬¡ï¼‰==========
                if (epoch + 1) % eval_interval == 0:
                    self._update_adaptive_weights(epoch, n_epochs)
                    # æ‰“å°å½“å‰è‡ªé€‚åº”æƒé‡ï¼ˆæ¯50è½®æ‰“å°ä¸€æ¬¡ï¼Œé¿å…è¾“å‡ºå¤ªå¤šï¼‰
                    if (epoch + 1) % 50 == 0:
                        print(f"\n  è‡ªé€‚åº”æƒé‡: sparse={self.adaptive_weights['sparse']:.3f}, "
                              f"flat={self.adaptive_weights['flat']:.3f}, "
                              f"knee={self.adaptive_weights['knee']:.3f}, "
                              f"rs={self.adaptive_weights['rs']:.3f}, "
                              f"rsh={self.adaptive_weights['rsh']:.3f}, "
                              f"boundary={self.adaptive_weights.get('boundary', 0.0):.3f}")
                
                # ğŸ”¥ æ·»åŠ è¯¦ç»†è¯Šæ–­ä¿¡æ¯ï¼ˆå‰20ä¸ªepochï¼‰
                if epoch < 20:
                    # æ‰“å°å½“å‰å‚æ•°å€¼ï¼ˆå¸®åŠ©è¯Šæ–­ï¼‰
                    params_str = ""
                    if len(p_eval) == 7:
                        params_str = f" | I_ph={p_eval[0]:.4f}, I01={p_eval[1]:.2e}, I02={p_eval[2]:.2e}, n1={p_eval[3]:.3f}, n2={p_eval[4]:.3f}, Rs={p_eval[5]:.4f}, Rsh={p_eval[6]:.2f}"
                    elif len(p_eval) == 5:
                        # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šæ˜¾ç¤º5ä¸ªå‚æ•° + å›ºå®šçš„n1å’Œn2
                        params_str = f" | I_ph={p_eval[0]:.4f}, I01={p_eval[1]:.2e}, I02={p_eval[2]:.2e}, n1={TrainingConfig.FIXED_N1_VALUE:.1f}(å›ºå®š), n2={TrainingConfig.FIXED_N2_VALUE:.1f}(å›ºå®š), Rs={p_eval[3]:.4f}, Rsh={p_eval[4]:.2f}"
                    else:
                        params_str = f" | I_ph={p_eval[0]:.4f}, I0={p_eval[1]:.2e}, n={p_eval[2]:.3f}, Rs={p_eval[3]:.4f}, Rsh={p_eval[4]:.2f}"
                    print(f"Epoch {epoch+1:4d} | eval f = {f_eval:.6e} | best f = {best_f:.6e}{params_str}", end="")
                else:
                    print(f"Epoch {epoch+1:4d} | eval f = {f_eval:.6e} | best f = {best_f:.6e}", end="")
                
                if improved:
                    print(" *")  # æ ‡è®°æœ‰æ”¹å–„
                else:
                    print(f" (no improve: {no_improve_count}/{early_stop_patience})")
                
            # ğŸ”¥ å‰10ä¸ªepochæ·»åŠ è¯Šæ–­ä¿¡æ¯
            if epoch < 10 and not improved:
                # æ£€æŸ¥å‚æ•°æ˜¯å¦å¡åœ¨è¾¹ç•Œ
                boundary_hits = []
                b = self.param_bounds
                if len(p_eval) == 7:
                    if abs(p_eval[0] - b[0, 0]) < 1e-6 or abs(p_eval[0] - b[0, 1]) < 1e-6:
                        boundary_hits.append("I_ph")
                    if abs(p_eval[1] - 10**np.log10(b[1, 0])) < 1e-10 or abs(p_eval[1] - 10**np.log10(b[1, 1])) < 1e-10:
                        boundary_hits.append("I01")
                    if abs(p_eval[2] - 10**np.log10(b[2, 0])) < 1e-10 or abs(p_eval[2] - 10**np.log10(b[2, 1])) < 1e-10:
                        boundary_hits.append("I02")
                    if not self.fix_n1 and (abs(p_eval[3] - b[3, 0]) < 1e-6 or abs(p_eval[3] - b[3, 1]) < 1e-6):
                        boundary_hits.append("n1")
                    if not self.fix_n2 and (abs(p_eval[4] - b[4, 0]) < 1e-6 or abs(p_eval[4] - b[4, 1]) < 1e-6):
                        boundary_hits.append("n2")
                    if abs(p_eval[5] - b[5, 0]) < 1e-6 or abs(p_eval[5] - b[5, 1]) < 1e-6:
                        boundary_hits.append("Rs")
                    if abs(p_eval[6] - b[6, 0]) < 1e-6 or abs(p_eval[6] - b[6, 1]) < 1e-6:
                        boundary_hits.append("Rsh")
                elif len(p_eval) == 5:
                    # ğŸ”¥ å›ºå®šn1å’Œn2æ¨¡å¼ï¼šåªæ£€æŸ¥5ä¸ªå¯è®­ç»ƒå‚æ•°
                    if abs(p_eval[0] - b[0, 0]) < 1e-6 or abs(p_eval[0] - b[0, 1]) < 1e-6:
                        boundary_hits.append("I_ph")
                    if abs(p_eval[1] - 10**np.log10(b[1, 0])) < 1e-10 or abs(p_eval[1] - 10**np.log10(b[1, 1])) < 1e-10:
                        boundary_hits.append("I01")
                    if abs(p_eval[2] - 10**np.log10(b[2, 0])) < 1e-10 or abs(p_eval[2] - 10**np.log10(b[2, 1])) < 1e-10:
                        boundary_hits.append("I02")
                    if abs(p_eval[3] - b[5, 0]) < 1e-6 or abs(p_eval[3] - b[5, 1]) < 1e-6:
                        boundary_hits.append("Rs")
                    if abs(p_eval[4] - b[6, 0]) < 1e-6 or abs(p_eval[4] - b[6, 1]) < 1e-6:
                        boundary_hits.append("Rsh")
                
                if boundary_hits:
                    print(f"   âš  è­¦å‘Šï¼šå‚æ•° {', '.join(boundary_hits)} å¡åœ¨è¾¹ç•Œï¼Œå¯èƒ½é™åˆ¶æœç´¢ç©ºé—´")
                else:
                    print(f"   æç¤ºï¼šå‰å‡ ä¸ªepochè¯¯å·®æ³¢åŠ¨æ˜¯æ­£å¸¸çš„ï¼ŒåŒäºŒæç®¡æ¨¡å‹éœ€è¦æ›´å¤šæ¢ç´¢æ—¶é—´")
                
                # é‡å¯æœºåˆ¶ï¼ˆä½¿ç”¨é…ç½®ç±»ï¼‰
                if no_improve_count >= TrainingConfig.RESTART_PATIENCE and \
                   no_improve_count % TrainingConfig.RESTART_PATIENCE == 0 and \
                   epoch < n_epochs - 10:
                    restart_count += 1
                    print(f"\nğŸ”„ é‡å¯æœºåˆ¶è§¦å‘ï¼ˆç¬¬{restart_count}æ¬¡ï¼‰ï¼šè¿ç»­{no_improve_count}è½®æœªæ”¹å–„")
                    # é€‚åº¦é‡ç½®ç½‘ç»œå‚æ•°
                    with torch.no_grad():
                        for name, param in self.actor.named_parameters():
                            if 'fc' in name and 'weight' in name:
                                noise = torch.randn_like(param) * TrainingConfig.RESTART_NOISE_SCALE
                                param.data += noise
                                param.data = torch.clamp(param.data, -2.0, 2.0)
                    print(f"   å·²æ·»åŠ éšæœºå™ªå£°ï¼ˆ{TrainingConfig.RESTART_NOISE_SCALE*100:.0f}%ï¼‰ï¼Œç»§ç»­è®­ç»ƒ...")
                    no_improve_count = 0
                
                # æ—©åœæ£€æŸ¥ï¼ˆå·²ç¦ç”¨ï¼šå…è®¸å……åˆ†æ¢ç´¢ï¼‰
                # ğŸ”¥ å·²ç¦ç”¨æ—©åœæœºåˆ¶ï¼šå…è®¸ä¼˜åŒ–å™¨å……åˆ†æ¢ç´¢æœç´¢ç©ºé—´
                # if no_improve_count >= early_stop_patience:
                #     print(f"\næ—©åœè§¦å‘ï¼šbest_f è¿ç»­ {no_improve_count} è½®æœªæ”¹å–„ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                #     print(f"  å½“å‰ best_f = {best_f:.6e}")
                #     break

        if best_params is None:
            _, _, best_params = self._run_episode(explore=False, current_epoch=n_epochs-1, total_epochs=n_epochs)
            best_f = objective_function(best_params, self.V, self.I_meas, self.I_min, self.I_max)
        return best_params, best_f, f_history


# =============================================================================
# 7. æ‹Ÿåˆç»“æœå¯è§†åŒ–
# =============================================================================

def plot_fit_result(
    V: np.ndarray,
    I_meas: np.ndarray,
    best_params: np.ndarray,
    I_min: float,
    I_max: float,
    best_f: float,
    f_history: List[float],
    save_path: Optional[str] = None,
) -> None:
    """
    ç»˜åˆ¶æ‹Ÿåˆç»“æœï¼šå·¦å›¾ IV æ›²çº¿ï¼ˆå®æµ‹ vs æ‹Ÿåˆï¼‰ï¼Œå³å›¾ç›®æ ‡å‡½æ•° f éšè¯„ä¼°è½®æ¬¡çš„å˜åŒ–ã€‚
    """
    I_sim = solar_cell_model(V, best_params, I_min, I_max)

    fig, axes = plt.subplots(1, 2, figsize=(10, 4))

    # å·¦å›¾ï¼šIV æ›²çº¿ â€” å®æµ‹ç‚¹ vs æ‹Ÿåˆæ›²çº¿
    ax1 = axes[0]
    ax1.scatter(V, I_meas, c="tab:blue", s=20, label="å®æµ‹", zorder=2)
    ax1.plot(V, I_sim, "r-", lw=1.5, label="æ‹Ÿåˆ", zorder=1)
    ax1.set_xlabel("ç”µå‹ V (V)")
    ax1.set_ylabel("ç”µæµ I (A)")
    ax1.set_title(f"IV æ›²çº¿ï¼šå®æµ‹ vs æ‹Ÿåˆ (f = {best_f:.4e})")
    ax1.legend(loc="best", fontsize=9)
    ax1.grid(True, alpha=0.3)
    ax1.ticklabel_format(style="scientific", axis="y", scilimits=(-2, 2))

    # å³å›¾ï¼šç›®æ ‡å‡½æ•° f éšè¯„ä¼°è½®æ¬¡
    ax2 = axes[1]
    n_evals = len(f_history)
    ax2.plot(range(1, n_evals + 1), f_history, "b-o", markersize=4, lw=0.8)
    ax2.set_xlabel("è¯„ä¼°è½®æ¬¡")
    ax2.set_ylabel("ç›®æ ‡å‡½æ•° f")
    ax2.set_title("ç›®æ ‡å‡½æ•° f éšè¯„ä¼°è½®æ¬¡å˜åŒ–")
    ax2.grid(True, alpha=0.3)
    if n_evals > 0 and min(f_history) < max(f_history):
        ax2.ticklabel_format(style="scientific", axis="y", scilimits=(-2, 2))

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches="tight")
        print(f"  å›¾åƒå·²ä¿å­˜: {save_path}")
    plt.show()


# =============================================================================
# 8. ä¸»å…¥å£
# =============================================================================

def main() -> None:
    # ğŸ”¥ å®Œå…¨è‡ªåŠ¨åŒ–ï¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®ç¼ºå¤±ï¼Œè‡ªåŠ¨å¢å¼ºï¼Œè‡ªåŠ¨è®­ç»ƒ
    # ç¡®ä¿å¯¹ä»»ä½•æ•°æ®éƒ½èƒ½æˆåŠŸæ‹Ÿåˆ
    base_dir = os.path.dirname(__file__)
    
    # ä¼˜å…ˆçº§1ï¼šä½¿ç”¨å¢å¼ºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    excel_path_augmented = os.path.join(base_dir, "5_augmented_spline.xls")
    excel_path_augmented_physics = os.path.join(base_dir, "5_augmented_physics.xls")
    excel_path_original = os.path.join(base_dir, "5.xls")
    
    # è‡ªåŠ¨é€‰æ‹©æ•°æ®æ–‡ä»¶
    if os.path.exists(excel_path_augmented):
        excel_path = excel_path_augmented
        print("âœ“ ä½¿ç”¨å¢å¼ºæ•°æ®ï¼ˆæ ·æ¡æ’å€¼ï¼‰:", excel_path)
    elif os.path.exists(excel_path_augmented_physics):
        excel_path = excel_path_augmented_physics
        print("âœ“ ä½¿ç”¨å¢å¼ºæ•°æ®ï¼ˆç‰©ç†æ¨¡å‹ï¼‰:", excel_path)
    else:
        excel_path = excel_path_original
        print("ğŸ“‚ åŠ è½½åŸå§‹æ•°æ®:", excel_path)
    
    # åŠ è½½æ•°æ®
    V, I_meas, _, _, I_min, I_max = load_excel_and_preprocess(excel_path)
    print(f"  V.shape={V.shape}, I.shape={I_meas.shape}, I_min={I_min:.2e}, I_max={I_max:.2e}")
    
    # ğŸ”¥ è‡ªåŠ¨æ£€æµ‹å¹¶å¢å¼ºæ•°æ®ï¼ˆå¦‚æœè†ç›–åŒºåŸŸæ•°æ®ç¼ºå¤±ï¼‰
    curve_feat = extract_curve_features(V, I_meas)
    V_oc = curve_feat[0]
    knee_low = 0.3 * V_oc
    knee_high = 0.7 * V_oc
    knee_mask = (V >= knee_low) & (V < knee_high)
    knee_count = np.sum(knee_mask)
    
    if knee_count < 5:
        print(f"\nâš  æ£€æµ‹åˆ°è†ç›–åŒºåŸŸæ•°æ®ç¼ºå¤±ï¼ˆåªæœ‰ {knee_count} ä¸ªç‚¹ï¼‰")
        print(f"   ğŸ”§ è‡ªåŠ¨è¿›è¡Œæ•°æ®å¢å¼º...")
        
        # å¯¼å…¥æ•°æ®å¢å¼ºå‡½æ•°
        try:
            from data_augmentation import augment_data_with_interpolation
            V, I_meas = augment_data_with_interpolation(V, I_meas, knee_region_points=15, method='spline')
            print(f"   âœ“ æ•°æ®å¢å¼ºå®Œæˆï¼šç°åœ¨æœ‰ {len(V)} ä¸ªæ•°æ®ç‚¹")
            
            # æ›´æ–°ç»Ÿè®¡
            knee_mask_new = (V >= knee_low) & (V < knee_high)
            knee_count_new = np.sum(knee_mask_new)
            print(f"   âœ“ è†ç›–åŒºåŸŸç°åœ¨æœ‰ {knee_count_new} ä¸ªæ•°æ®ç‚¹")
        except Exception as e:
            print(f"   âš  æ•°æ®å¢å¼ºå¤±è´¥ï¼š{e}")
            print(f"   â†’ ç»§ç»­ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆå½¢çŠ¶çº¦æŸä¼šè‡ªåŠ¨å¤„ç†æ•°æ®ç¼ºå¤±ï¼‰")
    else:
        print(f"\nâœ“ æ•°æ®è´¨é‡è‰¯å¥½ï¼ˆè†ç›–åŒºåŸŸæœ‰ {knee_count} ä¸ªæ•°æ®ç‚¹ï¼‰")

    # æ”¹è¿›ï¼šä½¿ç”¨æ›´ç¨³å®šçš„è¶…å‚æ•°ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›
    fitter = ACSolarFitter(
        V, I_meas, I_min, I_max,
        T_max=30,  # ä¿æŒ30ï¼Œç¡®ä¿è¶³å¤Ÿçš„ä¼˜åŒ–æ­¥æ•°ï¼Œä¸å½±å“è®­ç»ƒæ•ˆæœ
        gamma=0.99,
        alpha=0.5,
        lr_actor=3.5e-4,  # ğŸ”¥ å°å¹…æé«˜å­¦ä¹ ç‡ï¼šä»3e-4æé«˜åˆ°3.5e-4ï¼ˆ+17%ï¼‰ï¼Œå¸®åŠ©è·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼ˆå®é™…=5.25e-4ï¼‰
        lr_critic=4.5e-4,  # ğŸ”¥ å°å¹…æé«˜å­¦ä¹ ç‡ï¼šä»4e-4æé«˜åˆ°4.5e-4ï¼ˆ+12.5%ï¼‰ï¼Œå¸®åŠ©è·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼ˆå®é™…=6.75e-4ï¼‰
    )

    # ğŸ” æ£€æŸ¥è®­ç»ƒè®¾å¤‡ï¼ˆæ”¹è¿›ï¼šæ›´è¯¦ç»†çš„GPUä¿¡æ¯ï¼‰
    device_info = fitter.device
    print("\n" + "=" * 70)
    print("ğŸ–¥ï¸ è®­ç»ƒè®¾å¤‡ä¿¡æ¯")
    print("=" * 70)
    
    if str(device_info) == 'cpu':
        print("âš  è­¦å‘Šï¼šä½¿ç”¨CPUè®­ç»ƒï¼ˆä¼šå¾ˆæ…¢ï¼ï¼‰")
        print("\nå¯èƒ½çš„åŸå› ï¼š")
        print("   1. æ²¡æœ‰NVIDIA GPU")
        print("   2. CUDAé©±åŠ¨æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸åŒ¹é…")
        print("   3. PyTorchæœªç¼–è¯‘CUDAæ”¯æŒ")
        print("\nå»ºè®®ï¼š")
        print("   1. è¿è¡Œè¯Šæ–­è„šæœ¬: python check_gpu.py")
        print("   2. è¿è¡Œä¿®å¤è„šæœ¬: python fix_gpu.py")
        print("   3. æ£€æŸ¥NVIDIAé©±åŠ¨å’ŒCUDAå®‰è£…")
        print("\nå¿«é€Ÿæµ‹è¯•ï¼šå°†ä½¿ç”¨å‡å°‘çš„è®­ç»ƒå‚æ•°ï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰")
        use_fast_config = True
    else:
        print(f"âœ“ ä½¿ç”¨GPUè®­ç»ƒ: {device_info}")
        try:
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   GPUåç§°: {gpu_name}")
            print(f"   æ˜¾å­˜: {gpu_memory:.2f} GB")
            print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print("\nâœ… GPUç¯å¢ƒæ­£å¸¸ï¼Œè®­ç»ƒé€Ÿåº¦ä¼šå¿«å¾ˆå¤šï¼")
        except Exception as e:
            print(f"   âš  æ— æ³•è·å–GPUè¯¦ç»†ä¿¡æ¯: {e}")
        use_fast_config = False
    
    print("æ–¹æ¡ˆ B å¤šæ­¥ Actor-Critic è®­ç»ƒå¼€å§‹ (æ”¹è¿›ç‰ˆï¼šæå‡æ³›åŒ–èƒ½åŠ›å’Œè®­ç»ƒç¨³å®šæ€§)")
    print(f"  æ•°æ®ç‰¹å¾: I_sc={np.max(I_meas):.4f}A, V_oc={np.max(V):.4f}V")
    
    # æ ¹æ®è®¾å¤‡é€‰æ‹©è®­ç»ƒå‚æ•°
    if use_fast_config:
        # CPUè®­ç»ƒï¼šä½¿ç”¨å¿«é€Ÿé…ç½®ï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
        print("   ä½¿ç”¨å¿«é€Ÿé…ç½®ï¼ˆCPUæ¨¡å¼ï¼‰ï¼šepisodes_per_epoch=32, T_max=15")
        # ä¸´æ—¶ä¿®æ”¹T_maxï¼ˆä»…ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        fitter.T_max = 15
        best_params, best_f, f_history = fitter.fit(
            n_epochs=50,  # å‡å°‘è®­ç»ƒè½®æ•°
            episodes_per_epoch=32,  # å‡å°‘episodeæ•°ï¼ˆ128â†’32ï¼Œå‡å°‘4å€ï¼‰
            eval_interval=5,
            early_stop_patience=20,
            early_stop_min_delta=1e-5,  # æ”¾å®½æ—©åœæ¡ä»¶
        )
    else:
        # GPUè®­ç»ƒï¼šä½¿ç”¨ä¼˜åŒ–é…ç½®ï¼ˆå¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœï¼‰
        print("   ä½¿ç”¨ä¼˜åŒ–é…ç½®ï¼šepisodes_per_epoch=64, T_max=30")
        print("   æç¤ºï¼šè™½ç„¶GPUå·²å¯ç”¨ï¼Œä½†ç‰©ç†æ¨¡å‹è®¡ç®—åœ¨CPUä¸Šï¼Œè¿™æ˜¯æ€§èƒ½ç“¶é¢ˆ")
        print("   å¦‚æœè®­ç»ƒä»ç„¶æ…¢ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‡å°‘episodes_per_epochæˆ–T_max")
        best_params, best_f, f_history = fitter.fit(
            n_epochs=200,  # ä»300å‡å°‘åˆ°200ï¼Œå¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœ
            episodes_per_epoch=64,  # ä»128å‡å°‘åˆ°64ï¼Œé€Ÿåº¦æå‡çº¦2å€
            eval_interval=10,
            early_stop_patience=40,  # ä»50å‡å°‘åˆ°40
            early_stop_min_delta=1e-6,  # æ—©åœï¼šæ”¹å–„å°äº1e-6è®¤ä¸ºæ²¡æœ‰æ”¹å–„
        )

    print("\nä¼˜åŒ–å®Œæˆã€‚")
    print(f"  best f = {best_f:.6e}")
    # ğŸ”¥ åŒäºŒæç®¡æ¨¡å‹ï¼šè¾“å‡º7ä¸ªå‚æ•°ï¼ˆå¦‚æœå›ºå®šn1å’Œn2ï¼Œä¼šæ˜¾ç¤ºå›ºå®šå€¼ï¼‰
    if len(best_params) == 7:
        print("  æœ€ä¼˜å‚æ•° [I_ph, I01, I02, n1, n2, Rs, Rsh] (åŒäºŒæç®¡æ¨¡å‹):")
        param_names = ["I_ph", "I01", "I02", "n1", "n2", "Rs", "Rsh"]
        for i, name in enumerate(param_names):
            if name == "n1" and TrainingConfig.FIX_N1:
                print(f"    {name} = {TrainingConfig.FIXED_N1_VALUE:.6f} (å›ºå®š)")
            elif name == "n2" and TrainingConfig.FIX_N2:
                print(f"    {name} = {TrainingConfig.FIXED_N2_VALUE:.6f} (å›ºå®š)")
            else:
                fmt = ".6e" if "I0" in name or "I_ph" in name else ".6f"
                print(f"    {name} = {best_params[i]:{fmt}}")
    elif len(best_params) == 5:
        print("  æœ€ä¼˜å‚æ•° [I_ph, I01, I02, Rs, Rsh] (åŒäºŒæç®¡æ¨¡å‹ï¼Œn1å’Œn2å›ºå®š):")
        print(f"    I_ph = {best_params[0]:.6e} A")
        print(f"    I01  = {best_params[1]:.2e} A")
        print(f"    I02  = {best_params[2]:.2e} A")
        print(f"    n1   = {TrainingConfig.FIXED_N1_VALUE:.6f} (å›ºå®š)")
        print(f"    n2   = {TrainingConfig.FIXED_N2_VALUE:.6f} (å›ºå®š)")
        print(f"    Rs   = {best_params[3]:.6f} Î©")
        print(f"    Rsh  = {best_params[4]:.6f} Î©")
    else:
        print("  æœ€ä¼˜å‚æ•° [I_ph, I0, n, Rs, Rsh] (å•äºŒæç®¡æ¨¡å‹):")
        for name, val in zip(["I_ph", "I0", "n", "Rs", "Rsh"], best_params):
            fmt = ".6e" if "I0" in name or "I_ph" in name else ".6f"
            print(f"    {name} = {val:{fmt}}")

    # æ‹Ÿåˆç»“æœå¯è§†åŒ–
    save_path = os.path.join(os.path.dirname(__file__), "AC_fit_result.png")
    plot_fit_result(V, I_meas, best_params, I_min, I_max, best_f, f_history, save_path=save_path)


if __name__ == "__main__":
    main()
